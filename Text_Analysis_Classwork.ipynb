{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Εβδομάδα 1 - Εξόρυξη και προετοιμασία κειμένων \n",
    "\n",
    "\n",
    "**Θεωρία**\n",
    "\n",
    "Η εξόρυξη κειμένων γίνεται όλο και πιο σημαντική αυτά τα χρόνια καθώς έχουν αυξηθεί οι εφαρμογές ιστού που δημιουργούν τέτοια δεδομένα σε μεγάλες ποσότητες. Η εξόρυξη γνώσης γενικά περιγράφεται ως η εξερεύνηση και ανάλυση με αυτόματες ή ημιαυτόματες μεθόδους μεγάλου όγκου δεδομένων για την ανακάλυψη προτύπων και κανόνων με νόημα και εφαρμόζεται στην αναγνώριση σχέσεων σε μεγάλα πολυδιάστατα σύνολα δεδομένων. Ενώ κλασσικές εφαρμογές έχουν συγκεντρωθεί στην επεξεργασία και εξόρυξη κειμένου, η εμφάνιση αυτών των εφαρμογών ιστού απαιτεί καινούριες μεθόδους εξόρυξης και επεξεργασίας, όπως τη συσχέτιση αυτών, στη πολυγλωσσική πληροφορία και την εξόρυξη κειμένων - πολυμέσων όπως εικόνες ή βίντεο. Το κύριο χαρακτηριστικό που κάνει τα δεδομένα κειμένου να διαφέρουν από άλλες μορφές δεδομένων είναι η αραιότητα τους και η υψηλή τους διαστατικότητα. Για παράδειγμα μια συλλογή κειμένων μπορεί να αποτελείται από ένα λεξικό από χιλιάδες λέξεις (π.χ. το αγγλικό λεξικό Oxford Dictionary) αλλά ένα κείμενο μπορεί να περιέχει λίγες εκατοντάδες λέξεις.\n",
    "\n",
    "**Εφαρμογές και μέθοδοι εξόρυξης κειμένου**\n",
    "\n",
    "Η εξόρυξη κειμένου ή ανακάλυψη γνώσης από κείμενα αναφέρεται στη διαδικασία της εξαγωγής πληροφορίας υψηλής ποιότητας από κείμενα (π.χ. δομημένα όπως σε μορφή csv, ημιδομημένα όπως XML,JSON ή αδόμητα όπως κείμενα, βίντεο και εικόνες). Αυτή καλύπτει μια μεγάλη γκάμα θεματολογίας και αλγορίθμων για την ανάλυση κειμένων που επεκτείνεται σε πολλές κοινότητες όπως την ανάκτηση πληροφορίας, επεξεργασία φυσικής γλώσσας και μηχανική μάθηση.\n",
    "\n",
    "**Information Retrieval (IR)** : Η ανάκτηση πληροφορίας είναι η διαδικασία εύρεσης πηγών πληροφορίας (συνήθως κείμενα) από μια συλλογή αδόμητων συνόλων δεδομένων. Επομένως η ανάκτηση πληροφορίας επικεντρώνεται περισσότερο στην διευκόλυνση εύρεσης της πληροφορίας παρά την ανάλυση της και την εύρεση προτύπων σε αυτή. Η ανάκτηση πληροφορίας δίνει λιγότερη προτεραιότητα στην επεξεργασία ή στο μετασχηματισμό του κειμένου ενώ η εξόρυξη γνώσης πάει ένα βήμα παρακάτω και αναλύει την πληροφορία για καλύτερη κατανόηση αυτής.\n",
    "\n",
    "\n",
    "Ξεκινάμε με εισαγωγή κειμένων διαφόρων μορφών (PDFs, HTML, Word) και κατάλληλη προετοιμασία, ώστε να μπορούν να \"διαβαστούν\" και να αναλυθούν από τους υπολογιστές. \n",
    "\n",
    "Στο συγκεκριμένο notebook θα εξετάσουμε με ποιον τρόπο μπορούμε να ανακτήσουμε κέιμενα που βρίσκονται αναρτημένα στο διαδίκτυο (scraping), σε μορφή HTML, PDF και Word. Στην συνέχεια θα δοκιμάσουμε να περιηγηθούμε μέσω υπερσυνδέσεων για να δημιουργήσουμε ένα δείγμα από online περιεχόμενο, με την τεχνική \"spidering\" ή με την χρήση APIs, (Application Programming Interfaces), που παρέχονται ορισμένες φορές από τις διάφορες εταιρείες σε προγραμματιστές και παρέχουν πρόσβαση στο περιεχόμενό τους. \n",
    "\n",
    "Στην συνέχεια των μαθημάτων θα δοκιμάσουμε regular expressions, για να \"καθαρίσουμε\" τα κείμενα από ανεπιθύμητο περιεχόμενο όπως σημεία στίξης, μορφοποιήσεις κ.λπ.\n",
    "\n",
    "Στο τέλος θα εξερευνήσουμε τους τρόπους με τους οποίους μπορούμε να αποθηκέυσουμε το κείμενο, ώστε να είναι έτοιμο για ανάλυση. \n",
    "\n",
    "Για το συγκεκριμένο notebook θα χρειαστούμε τα εξής πακέτα: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Τα παρακάτω πακέτα θα εγξατασταθούν με την εντολή pip\n",
    "import requests #βιβλιοθήκη για http requests\n",
    "import bs4 #ονομάζεται `beautifulsoup4`, και είναι ένας html parser\n",
    "import pandas #δημιουργεί DataFrames\n",
    "import docx #διαβάζει MS doc files, για εγκατάσταση θέλουμε το `python-docx`\n",
    "\n",
    "#Πακέτο για επεξεργασία pdfs\n",
    "#Εγκατάσταση ως `pdfminer2`\n",
    "import pdfminer.pdfinterp\n",
    "import pdfminer.converter\n",
    "import pdfminer.layout\n",
    "import pdfminer.pdfpage\n",
    "\n",
    "#Tα παρακάτω υπάρχουν στην Python\n",
    "import re #regexs\n",
    "import urllib.parse #ένωση urls\n",
    "import io #κάνει τα http requests να μοιάζουν με αρχεία\n",
    "import json #API responses\n",
    "import os.path #Τσεκάρει ότι υπάρχουν τα αρχεία \n",
    "import os #Δημιουργεί directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Θα δουλέψουμε επίσης με τα παρακάτω αρχεία και urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia_base_url = 'https://en.wikipedia.org'\n",
    "wikipedia_content_analysis = 'https://en.wikipedia.org/wiki/Content_analysis'\n",
    "content_analysis_save = 'wikipedia_content_analysis.html'\n",
    "example_text_file = 'sometextfile.txt'\n",
    "information_extraction_pdf = 'https://github.com/Computational-Content-Analysis-2018/Data-Files/raw/master/1-intro/Content%20Analysis%2018.pdf'\n",
    "example_docx = 'https://github.com/Computational-Content-Analysis-2018/Data-Files/raw/master/1-intro/macs6000_connecting_to_midway.docx'\n",
    "example_docx_save = 'example.docx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping\n",
    "\n",
    "Πριν ξεκινήσει η ανάλυση περιεχομένου πρέπει να έχουμε το περιεχόμενο στην κατοχή μας. Μερικές φορές μπορεί να φτάσει στα χέρια μας ήδη \"καθαρό\" και έτοιμο για χρήση ως αρχείο κειμένου και άλλες φορές θα χρειαστεί να το κατεβάσουμε από το διαδίκτυο.\n",
    "\n",
    "Για αρχή ας δοκιμάσουμε να κατεβάσουμε μια σελίδα από το wikipedia για ανάλυση περιεχομένου. \n",
    "\n",
    "Η σελίδα βρίσκεται στο (https://en.wikipedia.org/wiki/Content_analysis)\n",
    "\n",
    "Θα χρησιμοποιήσουμε μία HTTP GET request για το συγκεκριμένο url, μια GET request είναι ένα απλό αίτημα στον server για να μας δώσει το περιεχόμενο αυτού του url. Ένα άλλο είδος είναι το POST request και πρόκειται για ένα αίτημα στο οποίο ζητάμε εμείς από τον server να πάρει ένα αρχείο που του δίνουμε. \n",
    "\n",
    "Παρόλο που η Python έχει ήδη μια βιβλιοθήκη για GET requests, εμείς θα χρησιμοποιούμε την \n",
    "[_requests_](http://docs.python-requests.org/en/master/) γιατί είναι πιο εύχρηστη."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#wikipedia_content_analysis = 'https://en.wikipedia.org/wiki/Content_analysis'\n",
    "requests.get(wikipedia_content_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`'Response [200]'` σημαίνει ότι ο server ανταποκρίθηκε σε αυτό που του ζητήσαμε. Αν παίρναμε άλλον αριθμό (π.χ. 404) θα σήμαινε ότι υπάρχει κάποιο error. \n",
    "\n",
    "Υπάρχει λίστα με όλους τους διαθέσιμους κωδικούς από HTTP response codes εδώ: \n",
    "[here](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes). \n",
    "\n",
    "To response διαθέτει όλα τα data που μας έστειλε ο server, το περιεχόμενο του website και το HTTP header. Εμάς μας ενδιαφέρει το περιεχόμενο που μπορούμε να το προσπελάσουμε με την εντολή `.text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<!DOCTYPE html>\n",
      "<html class=\"client-nojs\" lang=\"en\" dir=\"ltr\">\n",
      "<head>\n",
      "<meta charset=\"UTF-8\"/>\n",
      "<title>Content analysis - Wikipedia</title>\n",
      "<script>document.documentElement.className=\"client-js\";RLCONF={\"wgBreakFrames\":!1,\"wgSeparatorTransformTable\":[\"\",\"\"],\"wgDigitTransformTable\":[\"\",\"\"],\"wgDefaultDateFormat\":\"dmy\",\"wgMonthNames\":[\"\",\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\"],\"wgRequestId\":\"4532cf8a-22e9-4aa8-be50-e5be3974e988\",\"wgCSPNonce\":!1,\"wgCanonicalNamespace\":\"\",\"wgCanonicalSpecialPageName\":!1,\"wgNamespaceNumber\":0,\"wgPageName\":\"Content_analysis\",\"wgTitle\":\"Content analysis\",\"wgCurRevisionId\":953435023,\"wgRevisionId\":953435023,\"wgArticleId\":473317,\"wgIsArticle\":!0,\"wgIsRedirect\":!1,\"wgAction\":\"view\",\"wgUserName\":null,\"wgUserGroups\":[\"*\"],\"wgCategories\":[\"Articles needing expert attention with no reason or talk parameter\",\"Articles needing expert attention from April 2008\",\"All articles needing expert attention\",\n"
     ]
    }
   ],
   "source": [
    "wikiContentRequest = requests.get(wikipedia_content_analysis)\n",
    "print(wikiContentRequest.text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Αυτό δεν είναι το αποτέλεσμα που περιμέναμε, καθώς πρόκειται για την αρχή της  HTML του website. Η γλώσσα αυτή διαβάζεται από υπολογιστές, για το λόγο αυτό θα χρησιμοποιήσουμε έναν parser για να τη διαβάσουμε. Για το parsing θα χρησιμοποιήσουμε το [_Beautiful\n",
    "Soup_](https://www.crummy.com/software/BeautifulSoup/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Content analysis - Wikipedia\n",
      "document.documentElement.className=\"client-js\";RLCONF={\"wgBreakFrames\":!1,\"wgSeparatorTransformTable\":[\"\",\"\"],\"wgDigitTransformTable\":[\"\",\"\"],\"wgDefaultDateFormat\":\"d\n"
     ]
    }
   ],
   "source": [
    "wikiContentSoup = bs4.BeautifulSoup(wikiContentRequest.text, 'html.parser')\n",
    "print(wikiContentSoup.text[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Αυτό είναι καλύτερο από το προηγούμενο αποτέλεσμα, αλλά και πάλι περιέχει πολά κενά και όχι μόνο κείμενο. Αυτό συνέβη γιατί ζητήσαμε όλη την webpage, και όχι μόνο το κείμενο.\n",
    "\n",
    "Εμείς θέλουμε μόνο το κείμενο και για να πετύχουμε να πάρουμε μόνο αυτό, πρέπει να ελέγξουμε την html. Ένας εύκολος τρόπος να το κάνουμε αυτό είναι να επισκεφθούμε το website με έναν browser και να χρησιμοποιήσουμε το inspection ή το \"view source tool\". Σε περίπτωση που υπάρχει javascript ή κάποιο άλλο είδος δυναμικού loading στην σελίδα, τότε πρέπει να ελέγξουμε αυτό που λαμβάνει η Python και χρειαζόμαστε τη βιβλιοθήκη `requests`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#content_analysis_save = 'wikipedia_content_analysis.html'\n",
    "\n",
    "with open(content_analysis_save, mode='w', encoding='utf-8') as f:\n",
    "    f.write(wikiContentRequest.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Τώρα ας ανοίξουμε το αρχείο (`wikipedia_content_analysis.html`) που μόλις δημιουργήσαμε με τον web browser. Πρέπει να μοιάζει όπως το original αλλά χωρίς τις εικόνες και τη μορφοποίηση. \n",
    "\n",
    "Επειδή δεν υπάρχει τίποτα θέσφατο στη δημιουργία μιας ιστοσελίδας, το να καταλάβουμε τι πραγματικά είναι χρήσιμο για μας είναι Τέχνη. Κοιτώντας σε αυτή την σελίδα φαίνεται πως το κυρίως κείμενο είναι μέσα στα `<p>`(paragraph) tags που βρίσκονται μέσα στο `<body>` tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content analysis is a  studying documents and communication artifacts, which might be texts of various formats, pictures, audio or video. Social scientists use content analysis to examine patterns in communication in a replicable and systematic manner.[1] One of the key advantages of using content analysis to analyse social phenomena is its non-invasive nature, in contrast to simulating social experiences or collecting survey answers.\n",
      "\n",
      "Practices and philosophies of content analysis vary between academic disciplines. They all involve systematic reading or observation of texts or artifacts which are assigned labels (sometimes called codes) to indicate the presence of interesting, meaningful pieces of content.[2][3] By systematically labeling the content of a set of texts, researchers can analyse patterns of content quantitatively using statistical methods, or use qualitative methods to analyse meanings of content within texts.\n",
      "\n",
      "Computers are increasingly used in content analysis to automate the labeling (or coding) of documents. Simple computational techniques can provide descriptive data such as word frequencies and document lengths. Machine learning classifiers can greatly increase the number of texts that can be labeled, but the scientific utility of doing so is a matter of debate. Further, numerous computer-aided text analysis (CATA) computer programs are available that analyze text for pre-determined linguistic, semantic, and psychological characteristics.[4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "contentPTags = wikiContentSoup.body.findAll('p')\n",
    "for pTag in contentPTags[:3]:\n",
    "    print(pTag.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Τώρα έχουμε όλο το κείμενο χωρισμένο σε παραγράφους.  \n",
    "\n",
    "Μας μένει να κάνουμε κάτι ακόμα πριν αρχίσουμε την επεξεργασία, να βγάλουμε τα references indicators (`[2]`, `[3]` , κ.λπ). Για να γίνει αυτό χρειάζεται λίγο regular expression (regex)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       paragraph-text\n",
      "0   Content analysis is a  studying documents and ...\n",
      "1   Practices and philosophies of content analysis...\n",
      "2   Computers are increasingly used in content ana...\n",
      "3   Content analysis is best understood as a broad...\n",
      "4   The simplest and most objective form of conten...\n",
      "5   A further step in analysis is the distinction ...\n",
      "6   Quantitative content analysis highlights frequ...\n",
      "7   Siegfried Kracauer provides a critique of quan...\n",
      "8   More generally, content analysis is research u...\n",
      "9   By having contents of communication available ...\n",
      "10  Computer-assisted analysis can help with large...\n",
      "11  Robert Weber notes: \"To make valid inferences ...\n",
      "12  There are five types of texts in content analy...\n",
      "13  Over the years, content analysis has been appl...\n",
      "14  In recent times, particularly with the advent ...\n",
      "15  Quantitative content analysis has enjoyed a re...\n",
      "16  Content analysis can also be described as stud...\n",
      "17  Manifest content is readily understandable at ...\n",
      "18  Holsti groups fifteen uses of content analysis...\n",
      "19  He also places these uses into the context of ...\n",
      "20  The following table shows fifteen uses of cont...\n",
      "21  The process of the initial coding scheme or ap...\n",
      "22  With either approach above, immersing oneself ...\n",
      "23                                                 \\n\n"
     ]
    }
   ],
   "source": [
    "contentParagraphs = []\n",
    "for pTag in contentPTags:\n",
    "    contentParagraphs.append(re.sub(r'\\[\\d+\\]', '', pTag.text))\n",
    "\n",
    "#μετατροπή σε DataFrame\n",
    "contentParagraphsDF = pandas.DataFrame({'paragraph-text' : contentParagraphs})\n",
    "print(contentParagraphsDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Τώρα έχουμε ένα `DataFrame` που περιέχει όλα τα σχετικά κείμενα από την ιστοσελίδα. \n",
    "\n",
    "Επειδή δεν είστε ακόμα experts σε regex, πρόκειται για έναν τρόπο να πραγματοποιούμε συγκεκριμένες αναζητήσεις μέσα στο κείμενο. \n",
    "\n",
    "Μια μηχανή regex αντιλαμβάνεται το search pattern, στην παραπάνω περίπτωση το `'\\[\\d+\\]'` και κάποιο string από τα paragraph texts που έχουμε ορίσει. Στην συνέχεια τσεκάρει ένα ένα τα γράμματα από το  input string για να ελέγξει αν ταιριάζουν στην αναζήτηση. Εδώ το regex `'\\d'` ταιρίαζει αριθμούς ( (digits), ενώ το `'\\['` και το  `'\\]'` \"πιάνει\" τις αγκύλες σε κάθε πλευρά."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(36, 37), match='2'>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findNumber = r'\\d'\n",
    "regexResults = re.search(findNumber, 'not a number, not a number, numbers 2134567890, not a number')\n",
    "regexResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Στην Python το regex package (`re`) συνήθως επιστρέφει `Match` objects (μπορεί να έχουμε διάφορα pattern hits σε ένα μόνο `Match`), για να πάρουμε το string που ταίριαξε στο pattern που ζητήσαμε μπορούμε να χρησιμοποιήσουμε τη μέθοδο `.group()`. Επειδή θέλουμε το πρώτο θα ζητήσουμε το  0'. Στην πληροφορική ΠΑΝΤΑ το πρώτο είναι το 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(regexResults.group(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Πήραμε τον πρώτο αριθμό, αν θέλαμε όλο το block αριθμών θα προσθέταμε ένα `'+'` , το οποίο ζητά ένα ή παραπάνω εμφανίσεις του   προηγούμενου αριθμού. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2134567890\n"
     ]
    }
   ],
   "source": [
    "findNumbers = r'\\d+'\n",
    "regexResults = re.search(findNumbers, 'όχι αρθμός, όχι αρθμός, , αριθμοί 2134567890, όχι αρθμός ')\n",
    "print(regexResults.group(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Τώρα έχουμε όλο το block των αριθμών. \n",
    "\n",
    "Αν θέλετε να μάθετε περισσότερα για τα Python  regex δείτε [re docs](https://docs.python.org/3/library/re.html) και το μικρό \n",
    "[tutorial](https://docs.python.org/3/howto/regex.html#regex-howto)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">Άσκηση 1</span>\n",
    "<span style=\"color:red\"> Ακριβώς κάτω από αυτό το κελί προσθέστε νέα κελιά στα οποία θα περιγράφετε και στην συνέχεια θα κατεβάζετε περιεχόμενο από το διαδίκτυο που θα σχετίζεται με το τελικό σας project. Χρησιμοποιήστε beautiful soup και τουλάχιστον 5  regular expressions για να εξάγετε σχετικό και καθαρό κείμενο χωρίς κενά, αριθμούς που δεν χρειάζετε κ.λπ. Στην συνέχεια σώστε τις καθαρές προτάσεις κειμένου σε ένα pandas `Dataframe`.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Αράχνες (Spidering)\n",
    "\n",
    "Τι θα κάναμε αν θέλαμε διαφορετικές σελίδες από την wikipedia. Θα χρειαζόμασταν όλες τις διαφορετικές url για την καθεμιά από αυτές. Αυτό που μπορούμε να κάνουμε είναι να βρούμε σελίδες που συνδέονται με άλλες σελίδες μέσω κάποιου link. Ας προσπαθήσουμε να βρούμε τι  links υπάρχουν στην σελίδα που αναφέρεται στο content analysis.\n",
    "\n",
    "Για να προχωρήσουμε πρέπει πρώτα να αναζητήσουμε όλα τα `<a>` (anchor) tags με `href`\n",
    "(hyperlink references) που υπάρχουν μέσα στα `<p>` tags. Το `href` μπορεί να έχει διάφορες \n",
    "(http://stackoverflow.com/questions/4855168/what-is-href-and-why-is-it-used) μορφές (https://en.wikipedia.org/wiki/Hyperlink#Hyperlinks_in_HTML), οπότε πρέπει να είστε προσεκτικοί.\n",
    "\n",
    "Σε γενικές γραμμές θέλουμε να εξάγουμε ολόκληρα (absolute) ή σχετικά (relative) links. Ένα absolute link είναι αυτό που το ακολουθούμε απευθείας χωρίς μετατροπή, ενώ το relative link πρέπει πρώτα να ενωθεί με την βάση (base url) με append. Το Wikipedia χρησιμοποιεί relative urls για τα εσωτερικά links: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('https://en.wikipedia.org/wiki/Document', 0, 'documents'), ('https://en.wikipedia.org/wiki/Text_(literary_theory)', 1, 'texts'), ('https://en.wikipedia.org/wiki/Coding_(social_sciences)', 1, 'assigned labels (sometimes called codes)'), ('https://en.wikipedia.org/wiki/Semantics', 1, 'meaningful'), ('https://en.wikipedia.org/wiki/Text_(literary_theory)', 1, 'texts'), ('https://en.wikipedia.org/wiki/Quantitative_research', 1, 'quantitatively'), ('https://en.wikipedia.org/wiki/Statistics', 1, 'statistical methods'), ('https://en.wikipedia.org/wiki/Qualitative_research', 1, 'qualitative'), ('https://en.wikipedia.org/wiki/Text_(literary_theory)', 1, 'texts'), ('https://en.wikipedia.org/wiki/Machine_learning', 2, 'Machine learning')]\n"
     ]
    }
   ],
   "source": [
    "#wikipedia_base_url = 'https://en.wikipedia.org'\n",
    "\n",
    "otherPAgeURLS = []\n",
    "#Θέλουμε επίσης να ξέρουμε από ποθ προήλθαν τα links, άρα θέλουμε:\n",
    "#αριθμό παραγράφου\n",
    "#τη λέξη στην οποία βρίσκεται τo link\n",
    "for paragraphNum, pTag in enumerate(contentPTags):\n",
    "    # μόνο τα hrefs που οδηγούν σε wiki pages\n",
    "    tagLinks = pTag.findAll('a', href=re.compile('/wiki/'), class_=False)\n",
    "    for aTag in tagLinks:\n",
    "        #Πρέπει να εξάγουμε το url από το <a> tag\n",
    "        relurl = aTag.get('href')\n",
    "        linkText = aTag.text\n",
    "        #το wikipedia_base_url είναι η βάση στην οποία θα ενώσουμε με το urllib τα links\n",
    "        otherPAgeURLS.append((\n",
    "            urllib.parse.urljoin(wikipedia_base_url, relurl),\n",
    "            paragraphNum,\n",
    "            linkText,\n",
    "        ))\n",
    "print(otherPAgeURLS[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Θα προσθέσουμε αυτά τα 2 νέα στοιχεία στο DataFrame `contentParagraphsDF`, άρα πρέπει να προσθέσουμε  2 ακόμη στήλες για paragraph numbers και sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph-text</th>\n",
       "      <th>source</th>\n",
       "      <th>paragraph-number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Content analysis is a  studying documents and ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Practices and philosophies of content analysis...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Computers are increasingly used in content ana...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Content analysis is best understood as a broad...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The simplest and most objective form of conten...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A further step in analysis is the distinction ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Quantitative content analysis highlights frequ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Siegfried Kracauer provides a critique of quan...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>More generally, content analysis is research u...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>By having contents of communication available ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Computer-assisted analysis can help with large...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Robert Weber notes: \"To make valid inferences ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>There are five types of texts in content analy...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Over the years, content analysis has been appl...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>In recent times, particularly with the advent ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Quantitative content analysis has enjoyed a re...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Content analysis can also be described as stud...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Manifest content is readily understandable at ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Holsti groups fifteen uses of content analysis...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>He also places these uses into the context of ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>The following table shows fifteen uses of cont...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>The process of the initial coding scheme or ap...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>With either approach above, immersing oneself ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>\\n</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       paragraph-text  \\\n",
       "0   Content analysis is a  studying documents and ...   \n",
       "1   Practices and philosophies of content analysis...   \n",
       "2   Computers are increasingly used in content ana...   \n",
       "3   Content analysis is best understood as a broad...   \n",
       "4   The simplest and most objective form of conten...   \n",
       "5   A further step in analysis is the distinction ...   \n",
       "6   Quantitative content analysis highlights frequ...   \n",
       "7   Siegfried Kracauer provides a critique of quan...   \n",
       "8   More generally, content analysis is research u...   \n",
       "9   By having contents of communication available ...   \n",
       "10  Computer-assisted analysis can help with large...   \n",
       "11  Robert Weber notes: \"To make valid inferences ...   \n",
       "12  There are five types of texts in content analy...   \n",
       "13  Over the years, content analysis has been appl...   \n",
       "14  In recent times, particularly with the advent ...   \n",
       "15  Quantitative content analysis has enjoyed a re...   \n",
       "16  Content analysis can also be described as stud...   \n",
       "17  Manifest content is readily understandable at ...   \n",
       "18  Holsti groups fifteen uses of content analysis...   \n",
       "19  He also places these uses into the context of ...   \n",
       "20  The following table shows fifteen uses of cont...   \n",
       "21  The process of the initial coding scheme or ap...   \n",
       "22  With either approach above, immersing oneself ...   \n",
       "23                                                 \\n   \n",
       "\n",
       "                                            source  paragraph-number  \n",
       "0   https://en.wikipedia.org/wiki/Content_analysis                 0  \n",
       "1   https://en.wikipedia.org/wiki/Content_analysis                 1  \n",
       "2   https://en.wikipedia.org/wiki/Content_analysis                 2  \n",
       "3   https://en.wikipedia.org/wiki/Content_analysis                 3  \n",
       "4   https://en.wikipedia.org/wiki/Content_analysis                 4  \n",
       "5   https://en.wikipedia.org/wiki/Content_analysis                 5  \n",
       "6   https://en.wikipedia.org/wiki/Content_analysis                 6  \n",
       "7   https://en.wikipedia.org/wiki/Content_analysis                 7  \n",
       "8   https://en.wikipedia.org/wiki/Content_analysis                 8  \n",
       "9   https://en.wikipedia.org/wiki/Content_analysis                 9  \n",
       "10  https://en.wikipedia.org/wiki/Content_analysis                10  \n",
       "11  https://en.wikipedia.org/wiki/Content_analysis                11  \n",
       "12  https://en.wikipedia.org/wiki/Content_analysis                12  \n",
       "13  https://en.wikipedia.org/wiki/Content_analysis                13  \n",
       "14  https://en.wikipedia.org/wiki/Content_analysis                14  \n",
       "15  https://en.wikipedia.org/wiki/Content_analysis                15  \n",
       "16  https://en.wikipedia.org/wiki/Content_analysis                16  \n",
       "17  https://en.wikipedia.org/wiki/Content_analysis                17  \n",
       "18  https://en.wikipedia.org/wiki/Content_analysis                18  \n",
       "19  https://en.wikipedia.org/wiki/Content_analysis                19  \n",
       "20  https://en.wikipedia.org/wiki/Content_analysis                20  \n",
       "21  https://en.wikipedia.org/wiki/Content_analysis                21  \n",
       "22  https://en.wikipedia.org/wiki/Content_analysis                22  \n",
       "23  https://en.wikipedia.org/wiki/Content_analysis                23  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contentParagraphsDF['source'] = [wikipedia_content_analysis] * len(contentParagraphsDF['paragraph-text'])\n",
    "contentParagraphsDF['paragraph-number'] = range(len(contentParagraphsDF['paragraph-text']))\n",
    "\n",
    "contentParagraphsDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Μετά προσθέτουμε 2 νέες στήλες στο `Dataframe` και ορίζουμε ένα function για να φέρει κάθε linked page και να προσθέσει το κείμενο της στο DataFrame μας."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "contentParagraphsDF['source-paragraph-number'] = [None] * len(contentParagraphsDF['paragraph-text'])\n",
    "contentParagraphsDF['source-paragraph-text'] = [None] * len(contentParagraphsDF['paragraph-text'])\n",
    "\n",
    "def getTextFromWikiPage(targetURL, sourceParNum, sourceText):\n",
    "    #Φτιάχνουμε ένα dict στο οποίο θα σώσουμε τα data πριν τα αποθηκεύσουμε στο DataFrame\n",
    "    parsDict = {'source' : [], 'paragraph-number' : [], 'paragraph-text' : [], 'source-paragraph-number' : [],  'source-paragraph-text' : []}\n",
    "    #Τώρα παίρνουμε την σελίδα \n",
    "    r = requests.get(targetURL)\n",
    "    soup = bs4.BeautifulSoup(r.text, 'html.parser')\n",
    "    #Με το enumerating παίρνουμε τον αριθμό της παραγράφου\n",
    "    for parNum, pTag in enumerate(soup.body.findAll('p')):\n",
    "        #το ίδιο regex με πριν\n",
    "        parsDict['paragraph-text'].append(re.sub(r'\\[\\d+\\]', '', pTag.text))\n",
    "        parsDict['paragraph-number'].append(parNum)\n",
    "        parsDict['source'].append(targetURL)\n",
    "        parsDict['source-paragraph-number'].append(sourceParNum)\n",
    "        parsDict['source-paragraph-text'].append(sourceText)\n",
    "    return pandas.DataFrame(parsDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Και το τρέχουμε στην λίστα με τα link tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph-number</th>\n",
       "      <th>paragraph-text</th>\n",
       "      <th>source</th>\n",
       "      <th>source-paragraph-number</th>\n",
       "      <th>source-paragraph-text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Content analysis is a  studying documents and ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Practices and philosophies of content analysis...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Computers are increasingly used in content ana...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Content analysis is best understood as a broad...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>The simplest and most objective form of conten...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>A further step in analysis is the distinction ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Quantitative content analysis highlights frequ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Siegfried Kracauer provides a critique of quan...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>More generally, content analysis is research u...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>By having contents of communication available ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Computer-assisted analysis can help with large...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>Robert Weber notes: \"To make valid inferences ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>There are five types of texts in content analy...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>Over the years, content analysis has been appl...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>In recent times, particularly with the advent ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>Quantitative content analysis has enjoyed a re...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>Content analysis can also be described as stud...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>Manifest content is readily understandable at ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>Holsti groups fifteen uses of content analysis...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>He also places these uses into the context of ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>The following table shows fifteen uses of cont...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>The process of the initial coding scheme or ap...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>With either approach above, immersing oneself ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>\\n</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>A document is a written, drawn, presented, or ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Document</td>\n",
       "      <td>0</td>\n",
       "      <td>documents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>The concept of \"document\" has been defined by ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Document</td>\n",
       "      <td>0</td>\n",
       "      <td>documents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>The document had the right to change with in 5...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Document</td>\n",
       "      <td>0</td>\n",
       "      <td>documents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3</td>\n",
       "      <td>An often cited article concludes that \"the evo...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Document</td>\n",
       "      <td>0</td>\n",
       "      <td>documents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4</td>\n",
       "      <td>\"Document\" is defined in library and informati...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Document</td>\n",
       "      <td>0</td>\n",
       "      <td>documents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>Documents are sometimes classified as secret, ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Document</td>\n",
       "      <td>0</td>\n",
       "      <td>documents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>6</td>\n",
       "      <td>Standards are accepted for specific applicatio...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Document</td>\n",
       "      <td>0</td>\n",
       "      <td>documents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>7</td>\n",
       "      <td>Such standard documents can be drafted based o...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Document</td>\n",
       "      <td>0</td>\n",
       "      <td>documents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>8</td>\n",
       "      <td>The page layout of a document is the manner in...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Document</td>\n",
       "      <td>0</td>\n",
       "      <td>documents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>9</td>\n",
       "      <td>Traditionally, the medium of a document was pa...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Document</td>\n",
       "      <td>0</td>\n",
       "      <td>documents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>10</td>\n",
       "      <td>Historically, documents were inscribed with in...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Document</td>\n",
       "      <td>0</td>\n",
       "      <td>documents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>11</td>\n",
       "      <td>Contemporary electronic means of memorializing...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Document</td>\n",
       "      <td>0</td>\n",
       "      <td>documents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>12</td>\n",
       "      <td>Digital documents usually require a specific f...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Document</td>\n",
       "      <td>0</td>\n",
       "      <td>documents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>13</td>\n",
       "      <td>Documents in all forms frequently serve as mat...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Document</td>\n",
       "      <td>0</td>\n",
       "      <td>documents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "      <td>In literary theory, a text is any object that ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Text_(literary_t...</td>\n",
       "      <td>1</td>\n",
       "      <td>texts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>Within the field of literary criticism, \"text\"...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Text_(literary_t...</td>\n",
       "      <td>1</td>\n",
       "      <td>texts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2</td>\n",
       "      <td>Since the history of writing predates the conc...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Text_(literary_t...</td>\n",
       "      <td>1</td>\n",
       "      <td>texts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>3</td>\n",
       "      <td>The word text has its origins in Quintilian's ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Text_(literary_t...</td>\n",
       "      <td>1</td>\n",
       "      <td>texts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4</td>\n",
       "      <td>Relying on literary theory, the notion of text...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Text_(literary_t...</td>\n",
       "      <td>1</td>\n",
       "      <td>texts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>https://en.wikipedia.org/wiki/Text_(literary_t...</td>\n",
       "      <td>1</td>\n",
       "      <td>texts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0</td>\n",
       "      <td>In the social sciences, coding is an analytica...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Coding_(social_s...</td>\n",
       "      <td>1</td>\n",
       "      <td>assigned labels (sometimes called codes)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1</td>\n",
       "      <td>One purpose of coding is to transform the data...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Coding_(social_s...</td>\n",
       "      <td>1</td>\n",
       "      <td>assigned labels (sometimes called codes)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2</td>\n",
       "      <td>Some studies will employ multiple coders worki...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Coding_(social_s...</td>\n",
       "      <td>1</td>\n",
       "      <td>assigned labels (sometimes called codes)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>3</td>\n",
       "      <td>One code should apply to only one category and...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Coding_(social_s...</td>\n",
       "      <td>1</td>\n",
       "      <td>assigned labels (sometimes called codes)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>4</td>\n",
       "      <td>=Quantitative approach==r quantitative analysi...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Coding_(social_s...</td>\n",
       "      <td>1</td>\n",
       "      <td>assigned labels (sometimes called codes)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>5</td>\n",
       "      <td>Questionnaire data can be pre-coded (process o...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Coding_(social_s...</td>\n",
       "      <td>1</td>\n",
       "      <td>assigned labels (sometimes called codes)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>6</td>\n",
       "      <td>In social sciences, spreadsheets such as Excel...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Coding_(social_s...</td>\n",
       "      <td>1</td>\n",
       "      <td>assigned labels (sometimes called codes)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>7</td>\n",
       "      <td>For disciplines in which a qualitative format ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Coding_(social_s...</td>\n",
       "      <td>1</td>\n",
       "      <td>assigned labels (sometimes called codes)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>8</td>\n",
       "      <td>Much of qualitative coding can be attributed t...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Coding_(social_s...</td>\n",
       "      <td>1</td>\n",
       "      <td>assigned labels (sometimes called codes)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>9</td>\n",
       "      <td>Coding is considered a process of discovery an...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Coding_(social_s...</td>\n",
       "      <td>1</td>\n",
       "      <td>assigned labels (sometimes called codes)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>10</td>\n",
       "      <td>The process can be done manually, which can be...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Coding_(social_s...</td>\n",
       "      <td>1</td>\n",
       "      <td>assigned labels (sometimes called codes)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>11</td>\n",
       "      <td>After assembling codes it is time to organize ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Coding_(social_s...</td>\n",
       "      <td>1</td>\n",
       "      <td>assigned labels (sometimes called codes)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>12</td>\n",
       "      <td>Creating memos during the coding process is in...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Coding_(social_s...</td>\n",
       "      <td>1</td>\n",
       "      <td>assigned labels (sometimes called codes)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>13</td>\n",
       "      <td>Hay, I. (2005). Qualitative research methods i...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Coding_(social_s...</td>\n",
       "      <td>1</td>\n",
       "      <td>assigned labels (sometimes called codes)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>14</td>\n",
       "      <td>Grbich, Carol. (2013). \"Qualitative Data Analy...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Coding_(social_s...</td>\n",
       "      <td>1</td>\n",
       "      <td>assigned labels (sometimes called codes)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>15</td>\n",
       "      <td>Saldaña, Johnny. (2015). \"The Coding Manual fo...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Coding_(social_s...</td>\n",
       "      <td>1</td>\n",
       "      <td>assigned labels (sometimes called codes)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    paragraph-number                                     paragraph-text  \\\n",
       "0                  0  Content analysis is a  studying documents and ...   \n",
       "1                  1  Practices and philosophies of content analysis...   \n",
       "2                  2  Computers are increasingly used in content ana...   \n",
       "3                  3  Content analysis is best understood as a broad...   \n",
       "4                  4  The simplest and most objective form of conten...   \n",
       "5                  5  A further step in analysis is the distinction ...   \n",
       "6                  6  Quantitative content analysis highlights frequ...   \n",
       "7                  7  Siegfried Kracauer provides a critique of quan...   \n",
       "8                  8  More generally, content analysis is research u...   \n",
       "9                  9  By having contents of communication available ...   \n",
       "10                10  Computer-assisted analysis can help with large...   \n",
       "11                11  Robert Weber notes: \"To make valid inferences ...   \n",
       "12                12  There are five types of texts in content analy...   \n",
       "13                13  Over the years, content analysis has been appl...   \n",
       "14                14  In recent times, particularly with the advent ...   \n",
       "15                15  Quantitative content analysis has enjoyed a re...   \n",
       "16                16  Content analysis can also be described as stud...   \n",
       "17                17  Manifest content is readily understandable at ...   \n",
       "18                18  Holsti groups fifteen uses of content analysis...   \n",
       "19                19  He also places these uses into the context of ...   \n",
       "20                20  The following table shows fifteen uses of cont...   \n",
       "21                21  The process of the initial coding scheme or ap...   \n",
       "22                22  With either approach above, immersing oneself ...   \n",
       "23                23                                                 \\n   \n",
       "24                 0  A document is a written, drawn, presented, or ...   \n",
       "25                 1  The concept of \"document\" has been defined by ...   \n",
       "26                 2  The document had the right to change with in 5...   \n",
       "27                 3  An often cited article concludes that \"the evo...   \n",
       "28                 4  \"Document\" is defined in library and informati...   \n",
       "29                 5  Documents are sometimes classified as secret, ...   \n",
       "30                 6  Standards are accepted for specific applicatio...   \n",
       "31                 7  Such standard documents can be drafted based o...   \n",
       "32                 8  The page layout of a document is the manner in...   \n",
       "33                 9  Traditionally, the medium of a document was pa...   \n",
       "34                10  Historically, documents were inscribed with in...   \n",
       "35                11  Contemporary electronic means of memorializing...   \n",
       "36                12  Digital documents usually require a specific f...   \n",
       "37                13  Documents in all forms frequently serve as mat...   \n",
       "38                 0  In literary theory, a text is any object that ...   \n",
       "39                 1  Within the field of literary criticism, \"text\"...   \n",
       "40                 2  Since the history of writing predates the conc...   \n",
       "41                 3  The word text has its origins in Quintilian's ...   \n",
       "42                 4  Relying on literary theory, the notion of text...   \n",
       "43                 5                                                      \n",
       "44                 0  In the social sciences, coding is an analytica...   \n",
       "45                 1  One purpose of coding is to transform the data...   \n",
       "46                 2  Some studies will employ multiple coders worki...   \n",
       "47                 3  One code should apply to only one category and...   \n",
       "48                 4  =Quantitative approach==r quantitative analysi...   \n",
       "49                 5  Questionnaire data can be pre-coded (process o...   \n",
       "50                 6  In social sciences, spreadsheets such as Excel...   \n",
       "51                 7  For disciplines in which a qualitative format ...   \n",
       "52                 8  Much of qualitative coding can be attributed t...   \n",
       "53                 9  Coding is considered a process of discovery an...   \n",
       "54                10  The process can be done manually, which can be...   \n",
       "55                11  After assembling codes it is time to organize ...   \n",
       "56                12  Creating memos during the coding process is in...   \n",
       "57                13  Hay, I. (2005). Qualitative research methods i...   \n",
       "58                14  Grbich, Carol. (2013). \"Qualitative Data Analy...   \n",
       "59                15  Saldaña, Johnny. (2015). \"The Coding Manual fo...   \n",
       "\n",
       "                                               source source-paragraph-number  \\\n",
       "0      https://en.wikipedia.org/wiki/Content_analysis                    None   \n",
       "1      https://en.wikipedia.org/wiki/Content_analysis                    None   \n",
       "2      https://en.wikipedia.org/wiki/Content_analysis                    None   \n",
       "3      https://en.wikipedia.org/wiki/Content_analysis                    None   \n",
       "4      https://en.wikipedia.org/wiki/Content_analysis                    None   \n",
       "5      https://en.wikipedia.org/wiki/Content_analysis                    None   \n",
       "6      https://en.wikipedia.org/wiki/Content_analysis                    None   \n",
       "7      https://en.wikipedia.org/wiki/Content_analysis                    None   \n",
       "8      https://en.wikipedia.org/wiki/Content_analysis                    None   \n",
       "9      https://en.wikipedia.org/wiki/Content_analysis                    None   \n",
       "10     https://en.wikipedia.org/wiki/Content_analysis                    None   \n",
       "11     https://en.wikipedia.org/wiki/Content_analysis                    None   \n",
       "12     https://en.wikipedia.org/wiki/Content_analysis                    None   \n",
       "13     https://en.wikipedia.org/wiki/Content_analysis                    None   \n",
       "14     https://en.wikipedia.org/wiki/Content_analysis                    None   \n",
       "15     https://en.wikipedia.org/wiki/Content_analysis                    None   \n",
       "16     https://en.wikipedia.org/wiki/Content_analysis                    None   \n",
       "17     https://en.wikipedia.org/wiki/Content_analysis                    None   \n",
       "18     https://en.wikipedia.org/wiki/Content_analysis                    None   \n",
       "19     https://en.wikipedia.org/wiki/Content_analysis                    None   \n",
       "20     https://en.wikipedia.org/wiki/Content_analysis                    None   \n",
       "21     https://en.wikipedia.org/wiki/Content_analysis                    None   \n",
       "22     https://en.wikipedia.org/wiki/Content_analysis                    None   \n",
       "23     https://en.wikipedia.org/wiki/Content_analysis                    None   \n",
       "24             https://en.wikipedia.org/wiki/Document                       0   \n",
       "25             https://en.wikipedia.org/wiki/Document                       0   \n",
       "26             https://en.wikipedia.org/wiki/Document                       0   \n",
       "27             https://en.wikipedia.org/wiki/Document                       0   \n",
       "28             https://en.wikipedia.org/wiki/Document                       0   \n",
       "29             https://en.wikipedia.org/wiki/Document                       0   \n",
       "30             https://en.wikipedia.org/wiki/Document                       0   \n",
       "31             https://en.wikipedia.org/wiki/Document                       0   \n",
       "32             https://en.wikipedia.org/wiki/Document                       0   \n",
       "33             https://en.wikipedia.org/wiki/Document                       0   \n",
       "34             https://en.wikipedia.org/wiki/Document                       0   \n",
       "35             https://en.wikipedia.org/wiki/Document                       0   \n",
       "36             https://en.wikipedia.org/wiki/Document                       0   \n",
       "37             https://en.wikipedia.org/wiki/Document                       0   \n",
       "38  https://en.wikipedia.org/wiki/Text_(literary_t...                       1   \n",
       "39  https://en.wikipedia.org/wiki/Text_(literary_t...                       1   \n",
       "40  https://en.wikipedia.org/wiki/Text_(literary_t...                       1   \n",
       "41  https://en.wikipedia.org/wiki/Text_(literary_t...                       1   \n",
       "42  https://en.wikipedia.org/wiki/Text_(literary_t...                       1   \n",
       "43  https://en.wikipedia.org/wiki/Text_(literary_t...                       1   \n",
       "44  https://en.wikipedia.org/wiki/Coding_(social_s...                       1   \n",
       "45  https://en.wikipedia.org/wiki/Coding_(social_s...                       1   \n",
       "46  https://en.wikipedia.org/wiki/Coding_(social_s...                       1   \n",
       "47  https://en.wikipedia.org/wiki/Coding_(social_s...                       1   \n",
       "48  https://en.wikipedia.org/wiki/Coding_(social_s...                       1   \n",
       "49  https://en.wikipedia.org/wiki/Coding_(social_s...                       1   \n",
       "50  https://en.wikipedia.org/wiki/Coding_(social_s...                       1   \n",
       "51  https://en.wikipedia.org/wiki/Coding_(social_s...                       1   \n",
       "52  https://en.wikipedia.org/wiki/Coding_(social_s...                       1   \n",
       "53  https://en.wikipedia.org/wiki/Coding_(social_s...                       1   \n",
       "54  https://en.wikipedia.org/wiki/Coding_(social_s...                       1   \n",
       "55  https://en.wikipedia.org/wiki/Coding_(social_s...                       1   \n",
       "56  https://en.wikipedia.org/wiki/Coding_(social_s...                       1   \n",
       "57  https://en.wikipedia.org/wiki/Coding_(social_s...                       1   \n",
       "58  https://en.wikipedia.org/wiki/Coding_(social_s...                       1   \n",
       "59  https://en.wikipedia.org/wiki/Coding_(social_s...                       1   \n",
       "\n",
       "                       source-paragraph-text  \n",
       "0                                       None  \n",
       "1                                       None  \n",
       "2                                       None  \n",
       "3                                       None  \n",
       "4                                       None  \n",
       "5                                       None  \n",
       "6                                       None  \n",
       "7                                       None  \n",
       "8                                       None  \n",
       "9                                       None  \n",
       "10                                      None  \n",
       "11                                      None  \n",
       "12                                      None  \n",
       "13                                      None  \n",
       "14                                      None  \n",
       "15                                      None  \n",
       "16                                      None  \n",
       "17                                      None  \n",
       "18                                      None  \n",
       "19                                      None  \n",
       "20                                      None  \n",
       "21                                      None  \n",
       "22                                      None  \n",
       "23                                      None  \n",
       "24                                 documents  \n",
       "25                                 documents  \n",
       "26                                 documents  \n",
       "27                                 documents  \n",
       "28                                 documents  \n",
       "29                                 documents  \n",
       "30                                 documents  \n",
       "31                                 documents  \n",
       "32                                 documents  \n",
       "33                                 documents  \n",
       "34                                 documents  \n",
       "35                                 documents  \n",
       "36                                 documents  \n",
       "37                                 documents  \n",
       "38                                     texts  \n",
       "39                                     texts  \n",
       "40                                     texts  \n",
       "41                                     texts  \n",
       "42                                     texts  \n",
       "43                                     texts  \n",
       "44  assigned labels (sometimes called codes)  \n",
       "45  assigned labels (sometimes called codes)  \n",
       "46  assigned labels (sometimes called codes)  \n",
       "47  assigned labels (sometimes called codes)  \n",
       "48  assigned labels (sometimes called codes)  \n",
       "49  assigned labels (sometimes called codes)  \n",
       "50  assigned labels (sometimes called codes)  \n",
       "51  assigned labels (sometimes called codes)  \n",
       "52  assigned labels (sometimes called codes)  \n",
       "53  assigned labels (sometimes called codes)  \n",
       "54  assigned labels (sometimes called codes)  \n",
       "55  assigned labels (sometimes called codes)  \n",
       "56  assigned labels (sometimes called codes)  \n",
       "57  assigned labels (sometimes called codes)  \n",
       "58  assigned labels (sometimes called codes)  \n",
       "59  assigned labels (sometimes called codes)  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for urlTuple in otherPAgeURLS[:3]:\n",
    "    #Το ignore_index σημαίνει ότι οι δείκτες δεν θα διαγράφονται μετά από κάθε append\n",
    "    contentParagraphsDF = contentParagraphsDF.append(getTextFromWikiPage(*urlTuple),ignore_index=True)\n",
    "contentParagraphsDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <span style=\"color:red\">Άσκηση 2</span>\n",
    "<span style=\"color:red\"> Ακριβώς κάτω από αυτό το κελί προσθέστε νέα κελιά στα οποία θα φτιάξετε μια αράχνη (spider) για μία άλλη ιστοσελίδα σχετική με το τελικό σας project. Πιο συγκεκριμένα βρείτε urls στην βασική σελίδα και στην συνέχεια ακολουθήστε τα και εξάγετε το περιεχόμενο τους σε ένα pandas Dataframe. </span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API (Tumblr)\n",
    "\n",
    "Οι ιδιοκτήτες των websites δεν θέλουν να κάνετε scraping στα sites τους. Αν δεν είστε προσεκτικοί και 'χτυπάτε' συνεχόμενα το site, αυτό θα μοιάζει με DOS attack. Ορισμένα sites θέλουν αυτοματοποιημένα  εργαλεία για να έχουμε πρόσβαση στα δεδομένα τους και οι ίδιοι δημιουργούν [application programming interface\n",
    "(APIs)](https://en.wikipedia.org/wiki/Application_programming_interface). Ένα API\n",
    "συγκκριμενοποιεί τη διαδικασία με την οποία παρέχει τις πληροφορίες. Συνήθως γίνεται μέσω μιας [representational state transfer\n",
    "(REST)](https://en.wikipedia.org/wiki/Representational_state_transfer) web\n",
    "service.\n",
    "\n",
    "Ένα καλό παράδειγμα για εμάς είναι το [Tumblr](https://www.tumblr.com), που μας παρέχουν \n",
    "[simple RESTful API](https://www.tumblr.com/docs/en/api/v1) το οποίο μας επιτρέπει να διαβάζουμε posts χωρίς να χρειάζεται να κάνουμε δύσκολο html parsing.\n",
    "\n",
    "Μπορούμε εύκολα να πάρουμε τα πρώτα 20 posts από ένα blog μέσω μιας http GET request στο\n",
    "`'http://{blog}.tumblr.com/api/read/json'`, το `{blog}` είναι το όνομα του blog που στοχεύουμε. Ας πάρουμε μερικές δημοσιεύσεις από εδώ [http://lolcats-lol-\n",
    "cat.tumblr.com/](http://lolcats-lol-cat.tumblr.com/) (Το όνομα του Tumblr blog βρίσκεται στο URL 'lolcats-lol-cat')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var tumblr_api_read = {\"tumblelog\":{\"title\":\"One hour one pic lolcats\",\"description\":\"\",\"name\":\"lolcats-lol-cat\",\"timezone\":\"Europe\\/Paris\",\"cname\":false,\"feeds\":[]},\"posts-start\":0,\"posts-total\":3619,\"posts-type\":false,\"posts\":[{\"id\":\"617268206069071872\",\"url\":\"https:\\/\\/lolcats-lol-cat.tumblr.com\\/post\\/617268206069071872\",\"url-with-slug\":\"https:\\/\\/lolcats-lol-cat.tumblr.com\\/post\\/617268206069071872\\/bebo-meerkat-wants-to-say-something\",\"type\":\"photo\",\"date-gmt\":\"2020-05-05 10:00:34 GMT\",\"date\":\"Tue, 05 May 2020 12:00:34\",\"bookmarklet\":0,\"mobile\":0,\"feed-item\":\"\",\"from-feed-id\":0,\"unix-timestamp\":1588672834,\"format\":\"html\",\"reblog-key\":\"Tl2Jg6Ct\",\"slug\":\"bebo-meerkat-wants-to-say-something\",\"is-submission\":false,\"like-button\":\"<div class=\\\"like_button\\\" data-post-id=\\\"617268206069071872\\\" data-blog-name=\\\"lolcats-lol-cat\\\" id=\\\"like_button_617268206069071872\\\"><iframe id=\\\"like_iframe_617268206069071872\\\" src=\\\"https:\\/\\/assets.tumblr.com\\/assets\\/html\\/like_iframe.html?_v=66c22ab5\n"
     ]
    }
   ],
   "source": [
    "tumblrAPItarget = 'http://{}.tumblr.com/api/read/json'\n",
    "\n",
    "r = requests.get(tumblrAPItarget.format('lolcats-lol-cat'))\n",
    "\n",
    "print(r.text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Μπορεί να μην φαίνεται εύκολο, αλλά είναι πολύ ευκολότερο από την html! Αυτό που βλέπουμε είναι ένα\n",
    "[JSON](https://en.wikipedia.org/wiki/JSON) ένα 'human readable' κείμενο βασισμένο στα δεδομένα που στάλθηκαν σε ένα transmission format βασισμένο στην γλώσσα javascript. Ευτυχώς για εμάς, μπορούμε εύκολα να το μετατρέψουμε σε ένα python `dictionary`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['tumblelog', 'posts-start', 'posts-total', 'posts-type', 'posts'])\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "d = json.loads(r.text[len('var tumblr_api_read = '):-2])\n",
    "print(d.keys())\n",
    "print(len(d['posts']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Αν διαβάσουμε το [API specification](https://www.tumblr.com/docs/en/api/v1), θα δούμε ότι μπορούμε να πάρουμε πολλά πράγματα αν δwe\n",
    "will see there are a lot of things we can get if we add things to our GET\n",
    "request. First we can retrieve posts by their id number. Let's first get post\n",
    "`146020177084`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(tumblrAPItarget.format('lolcats-lol-cat'), params = {'id' : 146020177084})\n",
    "d = json.loads(r.text[len('var tumblr_api_read = '):-2])\n",
    "d['posts'][0].keys()\n",
    "d['posts'][0]['photo-url-1280']\n",
    "\n",
    "with open('lolcat.gif', 'wb') as f:\n",
    "    gifRequest = requests.get(d['posts'][0]['photo-url-1280'], stream = True)\n",
    "    f.write(gifRequest.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='lolcat.gif'>\n",
    "\n",
    "Αν δεν μπορείτε να το δείτε κάντε refresh. Τώρα μπορούμε να πάρουμε το κείμενο από όλα τα posts μαζί με τα σχετικά metadata, όπως το post date, το caption και τα tags. Επίσης μπορούμε να πάρουμε τα \n",
    "links των φωτογραφιών."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>photo-url</th>\n",
       "      <th>date</th>\n",
       "      <th>tags</th>\n",
       "      <th>photo-type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>617268206069071872</td>\n",
       "      <td>https://66.media.tumblr.com/6969bcfa1f05327a48...</td>\n",
       "      <td>Tue, 05 May 2020 12:00:34</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>617260664080203776</td>\n",
       "      <td>https://66.media.tumblr.com/93e542a32d8deca0ec...</td>\n",
       "      <td>Tue, 05 May 2020 10:00:41</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>617253222559694848</td>\n",
       "      <td>https://66.media.tumblr.com/b47ccfc588e0f3854f...</td>\n",
       "      <td>Tue, 05 May 2020 08:02:25</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>617177668891344896</td>\n",
       "      <td>https://66.media.tumblr.com/5bbf78171c3fbaea3a...</td>\n",
       "      <td>Mon, 04 May 2020 12:01:31</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>617170174889607168</td>\n",
       "      <td>https://66.media.tumblr.com/b47ccfc588e0f3854f...</td>\n",
       "      <td>Mon, 04 May 2020 10:02:24</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>616467954506301440</td>\n",
       "      <td>https://66.media.tumblr.com/65fb9193e9f162c93d...</td>\n",
       "      <td>Sun, 26 Apr 2020 16:00:55</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>616460510985060352</td>\n",
       "      <td>https://66.media.tumblr.com/55b3d7a5305cd150c9...</td>\n",
       "      <td>Sun, 26 Apr 2020 14:02:36</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>616452926146232320</td>\n",
       "      <td>https://66.media.tumblr.com/1aad32561a12bc4642...</td>\n",
       "      <td>Sun, 26 Apr 2020 12:02:02</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>616188729695059968</td>\n",
       "      <td>https://66.media.tumblr.com/a40792e8552b145b27...</td>\n",
       "      <td>Thu, 23 Apr 2020 14:02:45</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>616181036317032448</td>\n",
       "      <td>https://66.media.tumblr.com/dd0d842cd70ee2e5da...</td>\n",
       "      <td>Thu, 23 Apr 2020 12:00:28</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>616173468416901120</td>\n",
       "      <td>https://66.media.tumblr.com/1582c5304eba007da2...</td>\n",
       "      <td>Thu, 23 Apr 2020 10:00:11</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>616075465060401152</td>\n",
       "      <td>https://66.media.tumblr.com/f5d7f1b48a494cc621...</td>\n",
       "      <td>Wed, 22 Apr 2020 08:02:27</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>615803539907870720</td>\n",
       "      <td>https://66.media.tumblr.com/04372332259f402e54...</td>\n",
       "      <td>Sun, 19 Apr 2020 08:00:19</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>615758263621943296</td>\n",
       "      <td>https://66.media.tumblr.com/e9b015b9d68b0adecc...</td>\n",
       "      <td>Sat, 18 Apr 2020 20:00:41</td>\n",
       "      <td>[gif, lolcat, lolcats, cat, funny, 80s, kill, ...</td>\n",
       "      <td>gif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>615622346713219072</td>\n",
       "      <td>https://66.media.tumblr.com/997bfa5ff22e27caa1...</td>\n",
       "      <td>Fri, 17 Apr 2020 08:00:20</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>615539325455810560</td>\n",
       "      <td>https://66.media.tumblr.com/acfce529c07421523a...</td>\n",
       "      <td>Thu, 16 Apr 2020 10:00:45</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>615531766990667776</td>\n",
       "      <td>https://66.media.tumblr.com/3e01cddba50bbd27c9...</td>\n",
       "      <td>Thu, 16 Apr 2020 08:00:37</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>615524192185712640</td>\n",
       "      <td>https://66.media.tumblr.com/e2be3498d43224c772...</td>\n",
       "      <td>Thu, 16 Apr 2020 06:00:13</td>\n",
       "      <td>[gif, lolcat, lolcats, cat, funny]</td>\n",
       "      <td>gif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>615516656411787264</td>\n",
       "      <td>https://66.media.tumblr.com/e99851d752c095d2b8...</td>\n",
       "      <td>Thu, 16 Apr 2020 04:00:26</td>\n",
       "      <td>[gif, lolcat, lolcats, cat, funny]</td>\n",
       "      <td>gif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>615441152057999360</td>\n",
       "      <td>https://66.media.tumblr.com/947ff6b0f8987450be...</td>\n",
       "      <td>Wed, 15 Apr 2020 08:00:19</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>615154382228586496</td>\n",
       "      <td>https://66.media.tumblr.com/0d8f679e85ab310a97...</td>\n",
       "      <td>Sun, 12 Apr 2020 04:02:14</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>615003293374119936</td>\n",
       "      <td>https://66.media.tumblr.com/d05e62cfa8fab347ba...</td>\n",
       "      <td>Fri, 10 Apr 2020 12:00:45</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>614995720352710657</td>\n",
       "      <td>https://66.media.tumblr.com/a6e290b8471e09589f...</td>\n",
       "      <td>Fri, 10 Apr 2020 10:00:23</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>614723926577348608</td>\n",
       "      <td>https://66.media.tumblr.com/7292003ce717f2cecc...</td>\n",
       "      <td>Tue, 07 Apr 2020 10:00:20</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>614655994554941440</td>\n",
       "      <td>https://66.media.tumblr.com/90e5c1ab9abbe0ba00...</td>\n",
       "      <td>Mon, 06 Apr 2020 16:00:35</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>614648463725133824</td>\n",
       "      <td>https://66.media.tumblr.com/7ae866fa4717c2441c...</td>\n",
       "      <td>Mon, 06 Apr 2020 14:00:53</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>614640908693127168</td>\n",
       "      <td>https://66.media.tumblr.com/8e2642f3832f424e22...</td>\n",
       "      <td>Mon, 06 Apr 2020 12:00:48</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>614633334778281984</td>\n",
       "      <td>https://66.media.tumblr.com/935677e4f4444055ae...</td>\n",
       "      <td>Mon, 06 Apr 2020 10:00:25</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>614346537985785856</td>\n",
       "      <td>https://66.media.tumblr.com/4fd0402ebbe6d77e23...</td>\n",
       "      <td>Fri, 03 Apr 2020 06:01:54</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>614172929162346496</td>\n",
       "      <td>https://66.media.tumblr.com/f3edc9b70ea8f53592...</td>\n",
       "      <td>Wed, 01 Apr 2020 08:02:28</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>614006715843788800</td>\n",
       "      <td>https://66.media.tumblr.com/2f1d3c227d772abae2...</td>\n",
       "      <td>Mon, 30 Mar 2020 12:00:34</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>613999143816396800</td>\n",
       "      <td>https://66.media.tumblr.com/5da81307e4133be193...</td>\n",
       "      <td>Mon, 30 Mar 2020 10:00:13</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>613882150543097856</td>\n",
       "      <td>https://66.media.tumblr.com/5b7fd046e4e032b63f...</td>\n",
       "      <td>Sun, 29 Mar 2020 03:00:40</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>613648218790772736</td>\n",
       "      <td>https://66.media.tumblr.com/fd159a941c0b99437e...</td>\n",
       "      <td>Thu, 26 Mar 2020 12:02:25</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>613640644605427712</td>\n",
       "      <td>https://66.media.tumblr.com/68a47ad79485021420...</td>\n",
       "      <td>Thu, 26 Mar 2020 10:02:02</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>613632994416197632</td>\n",
       "      <td>https://66.media.tumblr.com/68a47ad79485021420...</td>\n",
       "      <td>Thu, 26 Mar 2020 08:00:26</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>613550046931288064</td>\n",
       "      <td>https://66.media.tumblr.com/4ccda1c45925280f3b...</td>\n",
       "      <td>Wed, 25 Mar 2020 10:02:01</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>613527304016101376</td>\n",
       "      <td>https://66.media.tumblr.com/d71dbe44d0e0a0a9f0...</td>\n",
       "      <td>Wed, 25 Mar 2020 04:00:32</td>\n",
       "      <td>[gif, lolcat, lolcats, cat, funny, horror, sur...</td>\n",
       "      <td>gif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>613391398025216001</td>\n",
       "      <td>https://66.media.tumblr.com/7340f74d05e9a02e91...</td>\n",
       "      <td>Mon, 23 Mar 2020 16:00:22</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>613383858120015872</td>\n",
       "      <td>https://66.media.tumblr.com/a62d278f09c76c2c6c...</td>\n",
       "      <td>Mon, 23 Mar 2020 14:00:31</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>613376296513355776</td>\n",
       "      <td>https://66.media.tumblr.com/e9fc398bb8aec154df...</td>\n",
       "      <td>Mon, 23 Mar 2020 12:00:20</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>613368855398612992</td>\n",
       "      <td>https://66.media.tumblr.com/c6c3702bc97ddda7e6...</td>\n",
       "      <td>Mon, 23 Mar 2020 10:02:03</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>613361205979004928</td>\n",
       "      <td>https://66.media.tumblr.com/cb4dadf92ae8b859e5...</td>\n",
       "      <td>Mon, 23 Mar 2020 08:00:28</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>613353661608919040</td>\n",
       "      <td>https://66.media.tumblr.com/04128fdd466ee549db...</td>\n",
       "      <td>Mon, 23 Mar 2020 06:00:33</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>613172558093860864</td>\n",
       "      <td>https://66.media.tumblr.com/e3bd9c6e961152b39e...</td>\n",
       "      <td>Sat, 21 Mar 2020 06:02:00</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>613104653341704192</td>\n",
       "      <td>https://66.media.tumblr.com/b4540fffcc5763e240...</td>\n",
       "      <td>Fri, 20 Mar 2020 12:02:41</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>613097071153725440</td>\n",
       "      <td>https://66.media.tumblr.com/bb76c33dae53e1ba2a...</td>\n",
       "      <td>Fri, 20 Mar 2020 10:02:10</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>613006438144622592</td>\n",
       "      <td>https://66.media.tumblr.com/77db242ca26a920840...</td>\n",
       "      <td>Thu, 19 Mar 2020 10:01:35</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>612998937580814336</td>\n",
       "      <td>https://66.media.tumblr.com/8b658177af23019e27...</td>\n",
       "      <td>Thu, 19 Mar 2020 08:02:22</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>612719484413837312</td>\n",
       "      <td>https://66.media.tumblr.com/020aa1a0c4d9500edd...</td>\n",
       "      <td>Mon, 16 Mar 2020 06:00:35</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "      <td>jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                          photo-url  \\\n",
       "0   617268206069071872  https://66.media.tumblr.com/6969bcfa1f05327a48...   \n",
       "1   617260664080203776  https://66.media.tumblr.com/93e542a32d8deca0ec...   \n",
       "2   617253222559694848  https://66.media.tumblr.com/b47ccfc588e0f3854f...   \n",
       "3   617177668891344896  https://66.media.tumblr.com/5bbf78171c3fbaea3a...   \n",
       "4   617170174889607168  https://66.media.tumblr.com/b47ccfc588e0f3854f...   \n",
       "5   616467954506301440  https://66.media.tumblr.com/65fb9193e9f162c93d...   \n",
       "6   616460510985060352  https://66.media.tumblr.com/55b3d7a5305cd150c9...   \n",
       "7   616452926146232320  https://66.media.tumblr.com/1aad32561a12bc4642...   \n",
       "8   616188729695059968  https://66.media.tumblr.com/a40792e8552b145b27...   \n",
       "9   616181036317032448  https://66.media.tumblr.com/dd0d842cd70ee2e5da...   \n",
       "10  616173468416901120  https://66.media.tumblr.com/1582c5304eba007da2...   \n",
       "11  616075465060401152  https://66.media.tumblr.com/f5d7f1b48a494cc621...   \n",
       "12  615803539907870720  https://66.media.tumblr.com/04372332259f402e54...   \n",
       "13  615758263621943296  https://66.media.tumblr.com/e9b015b9d68b0adecc...   \n",
       "14  615622346713219072  https://66.media.tumblr.com/997bfa5ff22e27caa1...   \n",
       "15  615539325455810560  https://66.media.tumblr.com/acfce529c07421523a...   \n",
       "16  615531766990667776  https://66.media.tumblr.com/3e01cddba50bbd27c9...   \n",
       "17  615524192185712640  https://66.media.tumblr.com/e2be3498d43224c772...   \n",
       "18  615516656411787264  https://66.media.tumblr.com/e99851d752c095d2b8...   \n",
       "19  615441152057999360  https://66.media.tumblr.com/947ff6b0f8987450be...   \n",
       "20  615154382228586496  https://66.media.tumblr.com/0d8f679e85ab310a97...   \n",
       "21  615003293374119936  https://66.media.tumblr.com/d05e62cfa8fab347ba...   \n",
       "22  614995720352710657  https://66.media.tumblr.com/a6e290b8471e09589f...   \n",
       "23  614723926577348608  https://66.media.tumblr.com/7292003ce717f2cecc...   \n",
       "24  614655994554941440  https://66.media.tumblr.com/90e5c1ab9abbe0ba00...   \n",
       "25  614648463725133824  https://66.media.tumblr.com/7ae866fa4717c2441c...   \n",
       "26  614640908693127168  https://66.media.tumblr.com/8e2642f3832f424e22...   \n",
       "27  614633334778281984  https://66.media.tumblr.com/935677e4f4444055ae...   \n",
       "28  614346537985785856  https://66.media.tumblr.com/4fd0402ebbe6d77e23...   \n",
       "29  614172929162346496  https://66.media.tumblr.com/f3edc9b70ea8f53592...   \n",
       "30  614006715843788800  https://66.media.tumblr.com/2f1d3c227d772abae2...   \n",
       "31  613999143816396800  https://66.media.tumblr.com/5da81307e4133be193...   \n",
       "32  613882150543097856  https://66.media.tumblr.com/5b7fd046e4e032b63f...   \n",
       "33  613648218790772736  https://66.media.tumblr.com/fd159a941c0b99437e...   \n",
       "34  613640644605427712  https://66.media.tumblr.com/68a47ad79485021420...   \n",
       "35  613632994416197632  https://66.media.tumblr.com/68a47ad79485021420...   \n",
       "36  613550046931288064  https://66.media.tumblr.com/4ccda1c45925280f3b...   \n",
       "37  613527304016101376  https://66.media.tumblr.com/d71dbe44d0e0a0a9f0...   \n",
       "38  613391398025216001  https://66.media.tumblr.com/7340f74d05e9a02e91...   \n",
       "39  613383858120015872  https://66.media.tumblr.com/a62d278f09c76c2c6c...   \n",
       "40  613376296513355776  https://66.media.tumblr.com/e9fc398bb8aec154df...   \n",
       "41  613368855398612992  https://66.media.tumblr.com/c6c3702bc97ddda7e6...   \n",
       "42  613361205979004928  https://66.media.tumblr.com/cb4dadf92ae8b859e5...   \n",
       "43  613353661608919040  https://66.media.tumblr.com/04128fdd466ee549db...   \n",
       "44  613172558093860864  https://66.media.tumblr.com/e3bd9c6e961152b39e...   \n",
       "45  613104653341704192  https://66.media.tumblr.com/b4540fffcc5763e240...   \n",
       "46  613097071153725440  https://66.media.tumblr.com/bb76c33dae53e1ba2a...   \n",
       "47  613006438144622592  https://66.media.tumblr.com/77db242ca26a920840...   \n",
       "48  612998937580814336  https://66.media.tumblr.com/8b658177af23019e27...   \n",
       "49  612719484413837312  https://66.media.tumblr.com/020aa1a0c4d9500edd...   \n",
       "\n",
       "                         date  \\\n",
       "0   Tue, 05 May 2020 12:00:34   \n",
       "1   Tue, 05 May 2020 10:00:41   \n",
       "2   Tue, 05 May 2020 08:02:25   \n",
       "3   Mon, 04 May 2020 12:01:31   \n",
       "4   Mon, 04 May 2020 10:02:24   \n",
       "5   Sun, 26 Apr 2020 16:00:55   \n",
       "6   Sun, 26 Apr 2020 14:02:36   \n",
       "7   Sun, 26 Apr 2020 12:02:02   \n",
       "8   Thu, 23 Apr 2020 14:02:45   \n",
       "9   Thu, 23 Apr 2020 12:00:28   \n",
       "10  Thu, 23 Apr 2020 10:00:11   \n",
       "11  Wed, 22 Apr 2020 08:02:27   \n",
       "12  Sun, 19 Apr 2020 08:00:19   \n",
       "13  Sat, 18 Apr 2020 20:00:41   \n",
       "14  Fri, 17 Apr 2020 08:00:20   \n",
       "15  Thu, 16 Apr 2020 10:00:45   \n",
       "16  Thu, 16 Apr 2020 08:00:37   \n",
       "17  Thu, 16 Apr 2020 06:00:13   \n",
       "18  Thu, 16 Apr 2020 04:00:26   \n",
       "19  Wed, 15 Apr 2020 08:00:19   \n",
       "20  Sun, 12 Apr 2020 04:02:14   \n",
       "21  Fri, 10 Apr 2020 12:00:45   \n",
       "22  Fri, 10 Apr 2020 10:00:23   \n",
       "23  Tue, 07 Apr 2020 10:00:20   \n",
       "24  Mon, 06 Apr 2020 16:00:35   \n",
       "25  Mon, 06 Apr 2020 14:00:53   \n",
       "26  Mon, 06 Apr 2020 12:00:48   \n",
       "27  Mon, 06 Apr 2020 10:00:25   \n",
       "28  Fri, 03 Apr 2020 06:01:54   \n",
       "29  Wed, 01 Apr 2020 08:02:28   \n",
       "30  Mon, 30 Mar 2020 12:00:34   \n",
       "31  Mon, 30 Mar 2020 10:00:13   \n",
       "32  Sun, 29 Mar 2020 03:00:40   \n",
       "33  Thu, 26 Mar 2020 12:02:25   \n",
       "34  Thu, 26 Mar 2020 10:02:02   \n",
       "35  Thu, 26 Mar 2020 08:00:26   \n",
       "36  Wed, 25 Mar 2020 10:02:01   \n",
       "37  Wed, 25 Mar 2020 04:00:32   \n",
       "38  Mon, 23 Mar 2020 16:00:22   \n",
       "39  Mon, 23 Mar 2020 14:00:31   \n",
       "40  Mon, 23 Mar 2020 12:00:20   \n",
       "41  Mon, 23 Mar 2020 10:02:03   \n",
       "42  Mon, 23 Mar 2020 08:00:28   \n",
       "43  Mon, 23 Mar 2020 06:00:33   \n",
       "44  Sat, 21 Mar 2020 06:02:00   \n",
       "45  Fri, 20 Mar 2020 12:02:41   \n",
       "46  Fri, 20 Mar 2020 10:02:10   \n",
       "47  Thu, 19 Mar 2020 10:01:35   \n",
       "48  Thu, 19 Mar 2020 08:02:22   \n",
       "49  Mon, 16 Mar 2020 06:00:35   \n",
       "\n",
       "                                                 tags photo-type  \n",
       "0                   [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "1                   [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "2                   [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "3                   [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "4                   [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "5                   [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "6                   [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "7                   [cat, cats, lol, lolcat, lolcats]        png  \n",
       "8                   [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "9                   [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "10                  [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "11                  [cat, cats, lol, lolcat, lolcats]        png  \n",
       "12                  [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "13  [gif, lolcat, lolcats, cat, funny, 80s, kill, ...        gif  \n",
       "14                  [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "15                  [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "16                  [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "17                 [gif, lolcat, lolcats, cat, funny]        gif  \n",
       "18                 [gif, lolcat, lolcats, cat, funny]        gif  \n",
       "19                  [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "20                  [cat, cats, lol, lolcat, lolcats]        png  \n",
       "21                  [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "22                  [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "23                  [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "24                  [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "25                  [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "26                  [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "27                  [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "28                  [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "29                  [cat, cats, lol, lolcat, lolcats]        png  \n",
       "30                  [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "31                  [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "32                  [cat, cats, lol, lolcat, lolcats]        png  \n",
       "33                  [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "34                  [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "35                  [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "36                  [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "37  [gif, lolcat, lolcats, cat, funny, horror, sur...        gif  \n",
       "38                  [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "39                  [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "40                  [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "41                  [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "42                  [cat, cats, lol, lolcat, lolcats]        png  \n",
       "43                  [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "44                  [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "45                  [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "46                  [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "47                  [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "48                  [cat, cats, lol, lolcat, lolcats]        jpg  \n",
       "49                  [cat, cats, lol, lolcat, lolcats]        jpg  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Βάζουμε έναν αριθμό max σε περίπτωση που το blog έχει εκατομμύρια εικόνες.\n",
    "#Tο max θα είναι πολλαπλάσιο του 50\n",
    "def tumblrImageScrape(blogName, maxImages = 200):\n",
    "    tumblrAPItarget = 'http://{}.tumblr.com/api/read/json'\n",
    "\n",
    "   \n",
    "    possiblePhotoSuffixes = [1280, 500, 400, 250, 100]\n",
    "\n",
    "    #Όλες τις πληροφορίες θα τις αποθηκεύσουμε στο τέλος σε ένα DataFrame.\n",
    "    #Στο Tumblr documentation μπορείτε να βρείτε πώς θα πάρετε και άλλες πληροφροίες.\n",
    "    #https://www.tumblr.com/docs/en/api/v1\n",
    "    postsData = {\n",
    "        'id' : [],\n",
    "        'photo-url' : [],\n",
    "        'date' : [],\n",
    "        'tags' : [],\n",
    "        'photo-type' : []\n",
    "    }\n",
    "\n",
    "    #Το Tumblr μας περιορίζει σε max 50 posts σε κάθε request\n",
    "    for requestNum in range(maxImages // 50):\n",
    "        requestParams = {\n",
    "            'start' : requestNum * 50,\n",
    "            'num' : 50,\n",
    "            'type' : 'photo'\n",
    "        }\n",
    "        r = requests.get(tumblrAPItarget.format(blogName), params = requestParams)\n",
    "        requestDict = json.loads(r.text[len('var tumblr_api_read = '):-2])\n",
    "        for postDict in requestDict['posts']:\n",
    "            #Παίρνουμε uncleaned data, δεν μπορούμε να τα εμπιστευτούμε.\n",
    "            #Δηλαδή, όλα τα posts δεν είναι απαραίτητο ότι περιέχουν όλες τις πληροφορίες που ζητάμε να πάρουμε.\n",
    "            try:\n",
    "                postsData['id'].append(postDict['id'])\n",
    "                postsData['date'].append(postDict['date'])\n",
    "                postsData['tags'].append(postDict['tags'])\n",
    "            except KeyError as e:\n",
    "                raise KeyError(\"Post {} from {} is missing: {}\".format(postDict['id'], blogName, e))\n",
    "\n",
    "            foundSuffix = False\n",
    "            for suffix in possiblePhotoSuffixes:\n",
    "                try:\n",
    "                    photoURL = postDict['photo-url-{}'.format(suffix)]\n",
    "                    postsData['photo-url'].append(photoURL)\n",
    "                    postsData['photo-type'].append(photoURL.split('.')[-1])\n",
    "                    foundSuffix = True\n",
    "                    break\n",
    "                except KeyError:\n",
    "                    pass\n",
    "            if not foundSuffix:\n",
    "                #Διαβάστε τα λάθη\n",
    "                raise KeyError(\"Post {} from {} is missing a photo url\".format(postDict['id'], blogName))\n",
    "\n",
    "    return pandas.DataFrame(postsData)\n",
    "tumblrImageScrape('lolcats-lol-cat', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Τώρα που έχουμε πολλά urls από φωτογραφίες θα μπορούσαμε να δοκιμάσουμε OCR και ίσως βρούμε μοτίβα στα memes με τις γάτες.\n",
    "\n",
    "# Αρχεία\n",
    "\n",
    "Όταν το κείμενο που αναζητούμε δεν βρίσκεται στο διαδίκτυο, τότε θα είναι σε μια μορφή αρχείου (*files*).\n",
    "\n",
    "## Raw αρχεία κειμένου (και κωδικοποίηση)\n",
    "\n",
    "Η τελείως βασική μορφή αποθήκευση ενός κειμένου είναι ως _raw text_ document. Ο πηγαίος κώδικας \n",
    "(`.py`, `.r`, κ.λπ) είναι συνήθως raw text όπως το (`.txt`) και άλλες επεκτάσεις όπως (.csv, .dat, κ.λπ.). Για να δούμε τι μορφής είναι ένα άγνωστο κείμενο μπορούμε να το ανοίξουμε με έναν \n",
    "text editor.\n",
    "\n",
    "Στην python δημιουργούμε ένα αρχείο κειμένου χρησιμοποιώντας το function `open()` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example_text_file = 'sometextfile.txt'\n",
    "#stringToWrite = 'A line\\nAnother line\\nA line with a few unusual symbols \\u2421 \\u241B \\u20A0 \\u20A1 \\u20A2 \\u20A3 \\u0D60\\n'\n",
    "stringToWrite = 'A line\\nAnother line\\nA line with a few unusual symbols ␡ ␛ ₠ ₡ ₢ ₣ ൠ\\n'\n",
    "\n",
    "with open(example_text_file, mode = 'w', encoding='utf-8') as f:\n",
    "    f.write(stringToWrite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Το `encoding='utf-8'` ορίζει τον τρόπο που εμφανίζονται οι χαρακτήρες [ASCII](https://en.wikipedia.org/wiki/ASCII) και εμφανίζει 128 χαρακτήρες. Στα αγγλικά και σε άλλες γλώσσες που χρησιμοποιούν το λατινικό αλφάβητο δεν υπάρχει κάποιο πρόβλημα, αλλά σε άλλες γλώσσες όπως τα ελληνικά ή τα κινέζικα πρέπει η κωδικοποίηση να είναι συμβατή και χρησιμοποιούμε το \n",
    "[Unicode](https://en.wikipedia.org/wiki/Unicode) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is with the correct encoding:\n",
      "A line\n",
      "Another line\n",
      "A line with a few unusual symbols ␡ ␛ ₠ ₡ ₢ ₣ ൠ\n",
      "\n",
      "This is with the wrong encoding:\n",
      "A line\n",
      "Another line\n",
      "A line with a few unusual symbols â¡ â â  â¡ â¢ â£ àµ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(example_text_file, encoding='utf-8') as f:\n",
    "    print(\"This is with the correct encoding:\")\n",
    "    print(f.read())\n",
    "\n",
    "with open(example_text_file, encoding='latin-1') as f:\n",
    "    print(\"This is with the wrong encoding:\")\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Παρατηρήστε ότι στο _latin-1_ οι unicode χαρακτήρες εμφανίζονται μπερδεμένοι και είναι πολλοί. Πρέπει πάντα να ελέγχετε ότι δουλέυετε με το σωστό encoding. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Μπορούμε να εισάγουμε πολλά αρχεία μαζί. Ας ρίξουμε μια ματιά στα κείμενα του Shakespeare που βρίσκονται στο `data` directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", and Train.]\n",
      "\n",
      "PUCK\n",
      "  If we shadows have offended,\n",
      "  Think but this,--and all is mended,--\n",
      "  That you have but slumber'd here\n",
      "  While these visions did appear.\n",
      "  And this weak and idle theme,\n",
      "  No more yielding but a dream,\n",
      "  Gentles, do not reprehend;\n",
      "  If you pardon, we will mend.\n",
      "  And, as I am an honest Puck,\n",
      "  If we have unearned luck\n",
      "  Now to 'scape the serpent's tongue,\n",
      "  We will make amends ere long;\n",
      "  Else the Puck a liar call:\n",
      "  So, good night unto you all.\n",
      "  Give me your hands, if we be friends,\n",
      "  And Robin shall restore amends.\n",
      "\n",
      "[Exit.]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "End of Project Gutenberg Etext of A Midsummer Night's Dream by Shakespeare\n",
      "PG has multiple editions of William Shakespeare's Complete Works\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('../../DS2019/Data/midsummer_nights_dream.txt') as f:\n",
    "    midsummer = f.read()\n",
    "print(midsummer[-700:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Προκειμένου να φορτώσουμε όλα τα αρχεία από το `../data/Shakespeare` μπορούμε να φτιάξουμε ένα for loop με `scandir`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetDir = '../../DS2019/Data' #Αλλάξτε το σύμφωνα με το δικό σας directory των κειμένων\n",
    "shakespearText = []\n",
    "shakespearFileName = []\n",
    "\n",
    "for file in (file for file in os.scandir(targetDir) if file.is_file() and not file.name.startswith('.')):\n",
    "    with open(file.path) as f:\n",
    "        shakespearText.append(f.read())\n",
    "    shakespearFileName.append(file.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ας τα βάλουμε σε ένα pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>julius_caesar.txt</th>\n",
       "      <td>Dramatis Personae\\n\\n  JULIUS CAESAR, Roman st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>as_you_like_it.txt</th>\n",
       "      <td>AS YOU LIKE IT\\n\\nby William Shakespeare\\n\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passionate_pilgrim.txt</th>\n",
       "      <td>THE PASSIONATE PILGRIM\\n\\nby William Shakespea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>king_henry_8.txt</th>\n",
       "      <td>KING HENRY THE EIGHTH\\n\\nby William Shakespear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>taming_of_the_shrew.txt</th>\n",
       "      <td>THE TAMING OF THE SHREW\\n\\nby William Shakespe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alls_well_that_ends_well.txt</th>\n",
       "      <td>All's Well, that Ends Well\\n\\nActus primus. Sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macbeth.txt</th>\n",
       "      <td>MACBETH\\n\\nby William Shakespeare\\n\\n\\n\\n\\nPer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>king_henry_6_p3.txt</th>\n",
       "      <td>The third Part of Henry the Sixt\\n\\nwith the d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coriolanus.txt</th>\n",
       "      <td>THE TRAGEDY OF CORIOLANUS\\n\\nby William Shakes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cymbeline.txt</th>\n",
       "      <td>The Tragedie of Cymbeline\\n\\nActus Primus. Sco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>much_ado_about_nothing.txt</th>\n",
       "      <td>MUCH ADO ABOUT NOTHING\\n\\nby William Shakspere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>king_john.txt</th>\n",
       "      <td>The life and death of King John\\n\\nActus Primu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lovers_complaint.txt</th>\n",
       "      <td>A LOVER'S COMPLAINT\\n\\nby William Shakespeare\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>romeo_and_juliet.txt</th>\n",
       "      <td>ROMEO AND JULIET\\n\\nby William Shakespeare\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two_gentlemen_of_verona.txt</th>\n",
       "      <td>THE TWO GENTLEMEN OF VERONA\\n\\nby William Shak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>king_lear.txt</th>\n",
       "      <td>The Tragedie of King Lear\\n\\n\\nActus Primus. S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>king_henry_6_p1.txt</th>\n",
       "      <td>Dramatis Personae\\n\\nKING HENRY the Sixth\\nDUK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phoenix_and_the_turtle.txt</th>\n",
       "      <td>THE PHOENIX AND THE TURTLE\\n\\nby William Shake...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>king_henry_4_p2.txt</th>\n",
       "      <td>KING HENRY IV, SECOND PART\\n\\nby William Shake...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timon_of_athens.txt</th>\n",
       "      <td>THE LIFE OF TIMON OF ATHENS\\n\\nby William Shak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tempest.txt</th>\n",
       "      <td>The Tempest\\n\\nActus primus, Scena prima.\\n\\nA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>measure_for_measure.txt</th>\n",
       "      <td>MEASURE FOR MEASURE\\n\\nby William Shakespeare\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rape_of_lucrece.txt</th>\n",
       "      <td>THE RAPE OF LUCRECE\\n\\nby William Shakespeare\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>othello.txt</th>\n",
       "      <td>THE TRAGEDY OF OTHELLO, MOOR OF VENICE\\n\\nby W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>king_richard_2.txt</th>\n",
       "      <td>DRAMATIS PERSONAE\\n\\n  KING RICHARD THE SECOND...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>titus_andronicus.txt</th>\n",
       "      <td>The Tragedie of Titus Andronicus\\n\\nActus Prim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merry_wives_of_windsor.txt</th>\n",
       "      <td>THE MERRY WIVES OF WINDSOR\\n\\nby William Shake...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twelth_night.txt</th>\n",
       "      <td>TWELFTH NIGHT;\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pericles_prince_of_tyre.txt</th>\n",
       "      <td>PERICLES PRINCE OF TYRE\\n\\nby William Shakespe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>king_henry_6_p2.txt</th>\n",
       "      <td>The second Part of Henry the Sixt\\n\\nwith the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sonnets.txt</th>\n",
       "      <td>THE SONNETS\\n\\nby William Shakespeare\\n\\n\\n\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loves_labors_lost.txt</th>\n",
       "      <td>LOVE'S LABOUR'S LOST\\n\\nby William Shakespeare...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>king_henry_5.txt</th>\n",
       "      <td>THE LIFE OF KING HENRY THE FIFTH\\n\\nby William...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>midsummer_nights_dream.txt</th>\n",
       "      <td>A MIDSUMMER NIGHT'S DREAM\\n\\nby William Shakes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merchant_of_venice.txt</th>\n",
       "      <td>The Merchant of Venice\\n\\nActus primus.\\n\\nEnt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hamlet.txt</th>\n",
       "      <td>The Tragedie of Hamlet\\n\\nActus Primus. Scoena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>king_richard_3.txt</th>\n",
       "      <td>KING RICHARD III\\n\\nby William Shakespeare\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comedy_of_errors.txt</th>\n",
       "      <td>DRAMATIS PERSONAE\\n\\nSOLINUS, Duke of Ephesus\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>troilus_and_cressida.txt</th>\n",
       "      <td>THE HISTORY OF TROILUS AND CRESSIDA\\n\\nby Will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anthonie_and_cleopatra.txt</th>\n",
       "      <td>The Tragedie of Anthonie, and Cleopatra\\n\\nAct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>winters_tale.txt</th>\n",
       "      <td>THE WINTER'S TALE\\n\\nby William Shakespeare\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>venus_and_adonis.txt</th>\n",
       "      <td>VENUS AND ADONIS\\n\\nby William Shakespeare\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>king_henry_4_p1.txt</th>\n",
       "      <td>The First Part of Henry the Fourth\\n\\nwith the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           text\n",
       "julius_caesar.txt             Dramatis Personae\\n\\n  JULIUS CAESAR, Roman st...\n",
       "as_you_like_it.txt            AS YOU LIKE IT\\n\\nby William Shakespeare\\n\\n\\n...\n",
       "passionate_pilgrim.txt        THE PASSIONATE PILGRIM\\n\\nby William Shakespea...\n",
       "king_henry_8.txt              KING HENRY THE EIGHTH\\n\\nby William Shakespear...\n",
       "taming_of_the_shrew.txt       THE TAMING OF THE SHREW\\n\\nby William Shakespe...\n",
       "alls_well_that_ends_well.txt  All's Well, that Ends Well\\n\\nActus primus. Sc...\n",
       "macbeth.txt                   MACBETH\\n\\nby William Shakespeare\\n\\n\\n\\n\\nPer...\n",
       "king_henry_6_p3.txt           The third Part of Henry the Sixt\\n\\nwith the d...\n",
       "coriolanus.txt                THE TRAGEDY OF CORIOLANUS\\n\\nby William Shakes...\n",
       "cymbeline.txt                 The Tragedie of Cymbeline\\n\\nActus Primus. Sco...\n",
       "much_ado_about_nothing.txt    MUCH ADO ABOUT NOTHING\\n\\nby William Shakspere...\n",
       "king_john.txt                 The life and death of King John\\n\\nActus Primu...\n",
       "lovers_complaint.txt          A LOVER'S COMPLAINT\\n\\nby William Shakespeare\\...\n",
       "romeo_and_juliet.txt          ROMEO AND JULIET\\n\\nby William Shakespeare\\n\\n...\n",
       "two_gentlemen_of_verona.txt   THE TWO GENTLEMEN OF VERONA\\n\\nby William Shak...\n",
       "king_lear.txt                 The Tragedie of King Lear\\n\\n\\nActus Primus. S...\n",
       "king_henry_6_p1.txt           Dramatis Personae\\n\\nKING HENRY the Sixth\\nDUK...\n",
       "phoenix_and_the_turtle.txt    THE PHOENIX AND THE TURTLE\\n\\nby William Shake...\n",
       "king_henry_4_p2.txt           KING HENRY IV, SECOND PART\\n\\nby William Shake...\n",
       "timon_of_athens.txt           THE LIFE OF TIMON OF ATHENS\\n\\nby William Shak...\n",
       "tempest.txt                   The Tempest\\n\\nActus primus, Scena prima.\\n\\nA...\n",
       "measure_for_measure.txt       MEASURE FOR MEASURE\\n\\nby William Shakespeare\\...\n",
       "rape_of_lucrece.txt           THE RAPE OF LUCRECE\\n\\nby William Shakespeare\\...\n",
       "othello.txt                   THE TRAGEDY OF OTHELLO, MOOR OF VENICE\\n\\nby W...\n",
       "king_richard_2.txt            DRAMATIS PERSONAE\\n\\n  KING RICHARD THE SECOND...\n",
       "titus_andronicus.txt          The Tragedie of Titus Andronicus\\n\\nActus Prim...\n",
       "merry_wives_of_windsor.txt    THE MERRY WIVES OF WINDSOR\\n\\nby William Shake...\n",
       "twelth_night.txt                                           TWELFTH NIGHT;\\n ...\n",
       "pericles_prince_of_tyre.txt   PERICLES PRINCE OF TYRE\\n\\nby William Shakespe...\n",
       "king_henry_6_p2.txt           The second Part of Henry the Sixt\\n\\nwith the ...\n",
       "sonnets.txt                   THE SONNETS\\n\\nby William Shakespeare\\n\\n\\n\\n ...\n",
       "loves_labors_lost.txt         LOVE'S LABOUR'S LOST\\n\\nby William Shakespeare...\n",
       "king_henry_5.txt              THE LIFE OF KING HENRY THE FIFTH\\n\\nby William...\n",
       "midsummer_nights_dream.txt    A MIDSUMMER NIGHT'S DREAM\\n\\nby William Shakes...\n",
       "merchant_of_venice.txt        The Merchant of Venice\\n\\nActus primus.\\n\\nEnt...\n",
       "hamlet.txt                    The Tragedie of Hamlet\\n\\nActus Primus. Scoena...\n",
       "king_richard_3.txt            KING RICHARD III\\n\\nby William Shakespeare\\n\\n...\n",
       "comedy_of_errors.txt          DRAMATIS PERSONAE\\n\\nSOLINUS, Duke of Ephesus\\...\n",
       "troilus_and_cressida.txt      THE HISTORY OF TROILUS AND CRESSIDA\\n\\nby Will...\n",
       "anthonie_and_cleopatra.txt    The Tragedie of Anthonie, and Cleopatra\\n\\nAct...\n",
       "winters_tale.txt              THE WINTER'S TALE\\n\\nby William Shakespeare\\n\\...\n",
       "venus_and_adonis.txt          VENUS AND ADONIS\\n\\nby William Shakespeare\\n\\n...\n",
       "king_henry_4_p1.txt           The First Part of Henry the Fourth\\n\\nwith the..."
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakespear_df = pandas.DataFrame({'text' : shakespearText}, index = shakespearFileName)\n",
    "shakespear_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Η αποθήκευση του κειμένου σε αυτή τη μορφή αποτελεί το πρώτο βήμα για την ανάλυση.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF\n",
    "\n",
    "Επίσης πολύ συχνά τα κείμενα βρίσκονται σε μορφή PDF και είναι αναρτημένα στο διαδίκτυο. Πρώτα πρέπει να τα κατεβάσουμε τοπικά με την Python. Ας δοκιμάσουμε να κατεβάσουμε ένα κεφάλαιο από το βιβλίο\n",
    "Speech and Language Processing_. Το chapter 21 αναλύει την έννοια του Information Extraction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%PDF-1.3\n",
      "%���������\n",
      "4 0 obj\n",
      "<< /Length 5 0 R /Filter /FlateDecode >>\n",
      "stream\n",
      "x\u0001�]۶�F�}�W�c����T���\u0017C\u000f�i�\u0019<t\u001f�b\u0001\u000fM�f\n",
      "Tn�\u0006<3_�\u000b",
      "�CDf�\u001d",
      "�J�N�i�\u000f�#�%.;.\u0019���\t?\u000f߄��7�]8������ux��}\u001b޾\u000fm����y��bǾ���\u0010�!\u001c",
      "\u000e���$�Ǯ���C�\u0007�F\u0006�����p�\u000f��5��1��1�P<�{�\u0010$�\u001a�/$�P�\f",
      "s�v��P\u001e",
      "gH?�����Q�~�*�:l��ˇ�m�ǰ��C�l����܊\u0017��E��\u001e",
      "���\u000f!�^�y��\u001am�$�Ý���wۡل׼�6w���ī�K�~؞���r��\u0010~\u001b\u001e",
      "?�ˡkO�;6IH�9{ԡ���\u0000]?�E�E�\u0012�~���.l������+��\u001c",
      "W�\u000e\u0002_�\u000e��\u0002\u0002��C��S�|�~\u0005C��N�3ӛB`8�ޚ\b\u0001j9���AZ�\u0004�\u00110�d�l^�\u000e�����SY\u0012\t�Ƨ��>\u000b",
      "q�ۇ&\n",
      "����.�����0���\u0015�;\u0000��>a8�$\f",
      "w�p��p����ST���\u000b",
      ".\u0000�7��@�\u0012���)�\u0013�&1�|���\u0002\u0004WՃ jOv�G2b�L8I��N�@\u0001\u001e",
      "gǍ�\u0004����\u0019�O�C��������IN@@���\u0002��\u0013}�8��+L����a�\u0005&ү\b�o\u0005\u0013�V(\u0019���0\f",
      "���+5\u001b�\n",
      "S\u001d",
      "fS&��<�2���\u001e",
      "��>l�V��&��=4⇤\u0019=\u001a�W��<�J\u0013Mo�\u001c",
      "���\"����d�C����[vY�|K\u001c",
      "{_ܔ\\��\u0017��%\u0001H�/@'�QA�+D�l��c��L�G�.��\t�̎�V�:f>���Aw\u0010K���o$`D\u0007��\u000b",
      "bE45�\u000b",
      "0\b�\u0015%th6h��\u0005���>*�2vQd\u0010\u0015�+M��Y}�Q���u�[���N�o'b\u0010��/u�.r'Z�\u0017��J�\u0019e8�v\u0013\u000b",
      "��;�\u001d",
      "�{T�\t\f",
      "�����^8�\u0014 \u001a\u0018 l<�E�<���b�����C8\f",
      "j��f��xB>\u0001K\u0010���\u0019��|\u001f\u0004w��f�|?�\u0001s̭\u0018��Y�'�Ip&�\"�\u000b",
      "A���f�?�\b!IYi���U�\"��y;�\u0007��#�\u000b",
      "\u000f�e3)�+B�&���\u001d",
      "�<\bE9I�g�/]\"D��yfC;e����Y^�z ��s'�)/�X�-HY��<ˬ�ݰ\n"
     ]
    }
   ],
   "source": [
    "#information_extraction_pdf = 'https://github.com/cathrinesot/raw/blob/master/21.pdf'\n",
    "\n",
    "infoExtractionRequest = requests.get(information_extraction_pdf, stream=True)\n",
    "print(infoExtractionRequest.text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Γράφει `'pdf'`, το οποίο είναι καλό σημάδι! Το υπόλοπο φαίνεται να έχει προβλήματα με το encoding. Αυτά που εμφανίζονται όμως δεν είναι πρόβλημα στο encoding, γιατί δεν υπάρχει κάποιο encoding για αυτά τα κομμάτια. Αυτό που χρειαζόμαστε είναι κάτι που να γνωρίζει από pdf και πώς να τα διαβάσει. Για αυτό θα χρησιμοποιήσουμε το\n",
    "[`PyPDF2`](https://github.com/mstamy2/PyPDF2), μια PDF processing library για\n",
    "Python 3.\n",
    "\n",
    "\n",
    "Ο παρακάτω κώδικας είναι ένα function το οποίο παίρνει το PDF file και επιστρέφει το κείμενο και θα το χρησιμοποιείτε αυτούσιο από δω και πέρα. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readPDF(pdfFile):\n",
    "    #Bασισμένο στον κώδικα http://stackoverflow.com/a/20905381/4955164\n",
    "    #Χρήση του utf-8\n",
    "    codec = 'utf-8'\n",
    "    rsrcmgr = pdfminer.pdfinterp.PDFResourceManager()\n",
    "    retstr = io.StringIO()\n",
    "    layoutParams = pdfminer.layout.LAParams()\n",
    "    device = pdfminer.converter.TextConverter(rsrcmgr, retstr, laparams = layoutParams, codec = codec)\n",
    "    #Χρειαζόμαστε έναν interpreter\n",
    "    interpreter = pdfminer.pdfinterp.PDFPageInterpreter(rsrcmgr, device)\n",
    "    password = ''\n",
    "    maxpages = 0\n",
    "    caching = True\n",
    "    pagenos=set()\n",
    "    for page in pdfminer.pdfpage.PDFPage.get_pages(pdfFile, pagenos, maxpages=maxpages, password=password,caching=caching, check_extractable=True):\n",
    "        interpreter.process_page(page)\n",
    "    device.close()\n",
    "    returnedString = retstr.getvalue()\n",
    "    retstr.close()\n",
    "    return returnedString"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Πρώτα χρειάζεται να πάρουμε το response object και να το μετατρέψουμε σε κάτι που να μοιάζει με αρχείο ώστε να μπορεί το pdfminer να το διαβάσει. Θέλουμε άρα από τη βιβλιοθήκη `io`', το `BytesIO`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "infoExtractionBytes = io.BytesIO(infoExtractionRequest.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Τώρα ας το δώσουμε στο pdfminer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Department of  Sociology \n",
      "\n",
      "THE UNIVERSITY OF CHICAGO \n",
      "\n",
      "SOCIOLOGY 40133 \n",
      "\n",
      "Computational Content Analysis \n",
      "\n",
      "Friday 1:00 – 3:50pm \n",
      "Winter 2017-2018 \n",
      "Classroom: Harper Memorial 130       \n",
      "http://chalk.uchicago.edu/ \n",
      "\n",
      " \n",
      "\n",
      "                                                                                           \n",
      "\n",
      "          Office: McGiffert 210 \n",
      "                                                    Tel.: 834-3612; jevans@uchicago.edu \n",
      "                                  Office Hours: Thursday 12:30-2:30pm \n",
      "\n",
      "     \n",
      "\n",
      "                \n",
      "\n",
      "        James A. Evans\n"
     ]
    }
   ],
   "source": [
    "print(readPDF(infoExtractionBytes)[:550])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Docs\n",
    "\n",
    "Ένας άλλο είδος αποθήκευσης κειμένου είναι το `.docx`, και πρόκειται για μια μορφή [XML](https://en.wikipedia.org/wiki/Office_Open_XML), και όπως στην HTML, χρειαζόμαστε ειδικό parser [`python-docx`](https://python-docx.readthedocs.io/en/latest/) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      "\n",
      "Accessing the Research Computing Center Resources\n",
      "\n",
      "To connect to the midway compute cluster to access your home directory and the macs60000 storage space, and utilize the HPC resources, you will either use a terminal client (with or without X11 forwarding capabilities) or the Linux remote desktop server software client (Thinlinc) to connect to the midway cluster. To submit jobs, monitor jobs, browse directories or do other computing you will need to connect through either the terminal or remote desktop. Setup and utilization of these clients will be discussed below in the context of your local platform’s architecture.\n",
      "SSH Client Setup & Remote Desktop Server\n"
     ]
    }
   ],
   "source": [
    "r = requests.get(example_docx, stream=True)\n",
    "d = docx.Document(io.BytesIO(r.content))\n",
    "for paragraph in d.paragraphs[:7]:\n",
    "    print(paragraph.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Χρειαζόμαστε ξανά το `io.BytesIO`, καθώς το `docx.Document` περιμένει να βρει ένα αρχείο. Ένας άλλος τρόπος είναι να σώσουμε το αρχείο και μετά να το εισάγουμε.  Αν το κάνουμε αυτό μπορούμε να σβήσουμε το αρχείο όταν τελειλωσουμε, ή να το σώσουμε τοπικά. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadIfNeeded(targetURL, outputFile, **openkwargs):\n",
    "    if not os.path.isfile(outputFile):\n",
    "        outputDir = os.path.dirname(outputFile)\n",
    "        #Πιο general os.mkdir()\n",
    "        if len(outputDir) > 0:\n",
    "            os.makedirs(outputDir, exist_ok = True)\n",
    "        r = requests.get(targetURL, stream=True)\n",
    "        #Βάζουμε το κλείσιμο του αρχείου \n",
    "        with open(outputFile, 'wb') as f:\n",
    "            f.write(r.content)\n",
    "    return open(outputFile, **openkwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Αυτό το function θα κατεβάσει, θα σώσει και θα ανοίξει το `outputFile` ως `outputFile` ή απλά θα το ανοίξει αν το `outputFile` υπάρχει. Το `open()` θα ανοίξει το αρχείο read only text με το τοπικό  encoding, το οποίο μπορεί να δημιουργήσει προβλήματα σε περίπτωση που το αρχείο δεν περιέχει κείμενο. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File is not a zip file\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    d = docx.Document(downloadIfNeeded(example_docx, example_docx_save))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Πρέπει να πούμε `open()` για να διαβαστεί σε binary mode (`'rb'`), γιαυτό προσθέσαμε το \n",
    "`**openkwargs`, μας επιτρέπει να βάλουμε  keyword arguments (kwargs) από το \n",
    "`downloadIfNeeded` στο `open()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How can we measure meaning?\n",
      "How can we coax the computer to read text?\n",
      "How can we gather text online?\n",
      " \n",
      "Orienting reading:\n",
      "Evans, James and Pedro Aceves.  2016. “Machine Translation: Mining Text for Social Theory”  Annual Review of Sociology 42:21-50. DOI: 10.1146/annurev-soc-081715-074206\n",
      "Question \n"
     ]
    }
   ],
   "source": [
    "d = docx.Document(downloadIfNeeded(example_docx, example_docx_save, mode = 'rb'))\n",
    "for paragraph in d.paragraphs[:7]:\n",
    "    print(paragraph.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Τώρα μπορούμε να διαβάσουμε το αρχείο `docx.Document` και να μην περίμενουμε να ξανακατέβει την επόμενη φορά."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <span style=\"color:red\">Άσκηση 3</span>\n",
    "<span style=\"color:red\"> Ακριβώς κάτω από αυτό το κελί προσθέστε νέα κελιά στα οποία θα εξάγετε και θα οργανώσετε κείμενα από αρχεία text, PDF or Word σε ένα pandas Dataframe.\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
